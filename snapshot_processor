#!/usr/bin/python
import dateutil.parser
import hashlib
import logging
import logging.handlers

import os
import pytz
import re
import signal
import subprocess
import sys
import time
import umsgpack
import urllib2

from ConfigParser import ConfigParser

import abc
import gammu.smsd
from datetime import datetime, timedelta
from dateutil import tz
from mimetypes import MimeTypes
from mplayer import Player
from pprint import pprint
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from pydrive.files import FileNotUploadedError
from Queue import Queue, Empty
from threading import Thread, Timer
from time import sleep
from umsgpack import UnpackException
from urllib import pathname2url, urlencode
from watchdog.events import FileSystemEventHandler, FileModifiedEvent
from watchdog.observers import Observer

sys.displayhook = pprint

APP = os.path.basename(__file__)
DIR = os.path.abspath(os.path.dirname(__file__))
# set the working directory for libraries that assume this (such as PyDrive)
os.chdir(DIR)
log = logging.getLogger(APP)

TTS_URL = 'http://translate.google.com/translate_tts'

config = ConfigParser()
config.optionxform = str
config.read([os.path.expanduser('~/.{}'.format(APP))])

gammu_cfg_file = config.get('sms', 'gammu-smsdrc')
smsd = gammu.smsd.SMSD(gammu_cfg_file)
gammu_cfg = ConfigParser()
gammu_cfg.optionxform = str
gammu_cfg.read(gammu_cfg_file)

snapshot_root = config.get('snapshots', 'root_dir')
heartbeat_interval_seconds = int(config.get('snapshots', 'heartbeat_interval_seconds'))
notification_interval_seconds = int(config.get('snapshots', 'notification_interval_seconds'))
snapshot_validity_seconds = int(config.get('snapshots', 'snapshot_validity_seconds'))

snapshot_queue = Queue()
cloud_storage = None

class Notifier(Thread):

    def __init__(self):
        super(Notifier, self).__init__()
        self.player = None
        self.daemon = True

        self.notification_queue = Queue()
        self.notification_timer = None
        self.deferred_notifications = Queue()

        self.tts_default_sound_file = config.get('app', 'tts_default_sound')

        sms_recipient_names = config.get('sms', 'recipient_names').split(',')
        sms_recipient_numbers = config.get('sms', 'recipient_numbers').split(',')
        self.sms_owners = dict(zip(sms_recipient_names, sms_recipient_numbers))

        not_before = config.get('informational_notifications', 'not_before')
        if not_before:
            self.informational_not_before = dateutil.parser.parse(not_before)
        not_after = config.get('informational_notifications', 'not_after')
        if not_after:
            self.informational_not_after = dateutil.parser.parse(not_after)
        self.any_time = False
        if not_before is None or not_after is None:
            self.any_time = True
        else:
            log.info('Informational notifications after {} will be deferred until {}.'.format(
                not_after,
                not_before))

    def run(self):
        # black-holding STDOUT causes properties to not work
        self.player = Player(stderr=open('/dev/null', 'w'), autospawn=True)
        while True:
            notification = None
            try:
                notification = self.notification_queue.get()
            except Exception as e:
                log.error(e)
            else:
                self.notification_queue.task_done()
            try:
                self.say(str(notification))
            except StandardError:
                log.exception("Unable to say message: '{}'".format(notification))
                self.play_file(os.path.join(DIR, self.tts_default_sound_file))

    def stop(self):
        if self.player:
            self.player.quit()

    def play_file(self, sound_file):
        self.player.loadfile(sound_file)
        delay = int(self.player.length)
        # block for the duration of this audio sample
        log.debug("Playing \"{}\" for {}s".format(sound_file, delay))
        sleep(delay)

    def say(self, message):
        msg_checksum = Notifier.checksum(message)
        log.debug("Checksum for \"{}\" is [{}]".format(message, msg_checksum))
        tts_file = "{}.mp3".format(msg_checksum)
        tts_path = os.path.join(DIR, tts_file)
        if os.path.isfile(tts_path) and os.path.getsize(tts_path) == 0:
            log.debug("Removing empty file {}".format(tts_path))
            os.remove(tts_path)
        log.debug("{} exists? {}".format(tts_path, os.path.isfile(tts_path)))
        if not os.path.isfile(tts_path):
            values = {'tl': 'en', 'q': message}
            data = urlencode(values)
            request = urllib2.Request(TTS_URL, data)
            request.add_header('User-agent', 'Mozilla/5.0')
            opener = urllib2.build_opener()
            log.debug("Fetching \"{}\" from {}".format(message, TTS_URL))
            f = open(tts_path, "wb")
            f.write(opener.open(request).read())
            f.close()
            log.debug("Written {} bytes to {}".format(os.path.getsize(tts_path), tts_path))
        # now play
        log.debug("Saying \"{}\"...".format(message))
        self.play_file(tts_path)

    def drain_deferred_notifications(self):
        # cancel the timer in case we're signalled instead
        self.notification_timer.cancel()
        log.info('Draining {} notifications deferred until now.'.format(self.deferred_notifications.qsize()))
        while not self.deferred_notifications.empty():
            try:
                self.notification_queue.put(self.deferred_notifications.get())
            except Exception as e:
                log.error(e)
            else:
                self.deferred_notifications.task_done()
        # Delete the expired the timer
        self.notification_timer = None

    def notify_voice(self, message, informational=False):
        #TODO: remove
        informational=False
        if not informational or self.any_time:
            self.notification_queue.put(message)
        else:
            # make a future date that is relative (after) now time.
            now = datetime.now().replace(tzinfo=tz.tzlocal())
            not_before = now.replace(
                hour=self.informational_not_before.hour,
                minute=self.informational_not_before.minute,
                second=0,
                microsecond=0)
            not_after = now.replace(
                hour=self.informational_not_after.hour,
                minute=self.informational_not_after.minute,
                second=0,
                microsecond=0)
            log.debug("Comparing now {} with 'not_after' of {}".format(now, not_after))
            if now < not_after:
                # go ahead
                log.debug('No notification deferral necessary.')
                self.notification_queue.put(message)
                return
            elif now >= not_after:
                # the not-before time may not be on the same day
                if now > not_before:
                    defer_until = not_before + timedelta(days=1)
            else:
                defer_until = not_before
            # defer the notification
            log.info("Deferring informational notification '{}' until {}".format(message, defer_until))
            self.deferred_notifications.put(message)
            if self.notification_timer is None:
                # now calculate the sleep time based on the deferral
                delay = defer_until - now
                log.debug('Deferring notifications for {} hours.'.format(delay.seconds / 3600))
                self.notification_timer = Timer(delay.seconds, self.drain_deferred_notifications)

    @staticmethod
    def send_sms(recipient, message, flash=False):
        sms_class = 1
        if flash:
            sms_class = 0
        message = {
            'Text': message,
            'SMSC': {'Location': 1},
            'Number': recipient,
            'Class': sms_class
        }
        smsd.InjectSMS([message])

    @staticmethod
    def checksum(message):
        m = hashlib.md5()
        m.update(message)
        return m.hexdigest()

notifier = None


class Snapshot(object):
    __metaclass__ = abc.ABCMeta

    def __init__(self, source_label, file_path, validity_seconds):
        self.source_label = source_label
        self.file_path = file_path
        self.validity_seconds = validity_seconds

    @abc.abstractproperty
    def timestamp(self):
        return NotImplemented

    @abc.abstractproperty
    def is_expired(self):
        return NotImplemented

    @abc.abstractproperty
    def data(self):
        return NotImplemented

    @abc.abstractproperty
    def device_names(self):
        return NotImplemented

    @abc.abstractproperty
    def devices(self):
        return NotImplemented

    @abc.abstractproperty
    def source(self):
        return NotImplemented


class SampledSnapshot(Snapshot):

    def __init__(self, source_label, file_path, validity_seconds):
        super(SampledSnapshot, self).__init__(
            source_label=source_label,
            file_path=file_path,
            validity_seconds=validity_seconds)
        f = open(file_path)
        self.snapshot_data = umsgpack.unpack(f)
        self.timestamp_data = dateutil.parser.parse(self.snapshot_data['timestamp'])
        if self.timestamp_data.tzinfo is None:
            self.timestamp_data = self.timestamp_data.replace(tzinfo=tz.tzlocal())
        if 'data' in self.snapshot_data:
            self.devices_data = self.snapshot_data['data']
        else:
            self.devices_data = None

    @property
    def timestamp(self):
        return self.timestamp_data

    @property
    def is_expired(self):
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        return now - self.timestamp_data > timedelta(seconds=self.validity_seconds)

    @property
    def data(self):
        return self.snapshot_data

    @property
    def device_names(self):
        if self.devices_data is None:
            return None
        names = []
        for device_name in self.devices_data.keys():
            names.append(' '.join([self.source_label, device_name]))
        return names

    @property
    def devices(self):
        if self.devices_data is None:
            return {}
        return self.devices_data

    @property
    def source(self):
        return self.source_label

    def __str__(self):
        string = "{} at {}".format(self.source_label, self.timestamp.strftime('%X %x %Z'))
        if self.devices:
            return string + ": {} devices: {}".format(
                len(self.devices), ','.join(self.devices.keys()))
        return string


class ImageSnapshot(Snapshot):

    def __init__(self, source_label, file_path, validity_seconds):
        super(ImageSnapshot, self).__init__(
            source_label=source_label,
            file_path=file_path,
            validity_seconds=validity_seconds)
        # default timestamp data to 'now'
        self.timestamp_data = datetime.utcnow().replace(tzinfo=pytz.utc)
        try:
            file_base_name = os.path.splitext(os.path.basename(file_path))[0]
            if '_' in file_base_name:
                date_string = file_base_name.split('_')[1]
            else:
                date_string = file_base_name
            self.timestamp_data = dateutil.parser.parse(date_string)
            if self.timestamp_data.tzinfo is None:
                self.timestamp_data = self.timestamp_data.replace(tzinfo=tz.tzlocal())
            log.debug("Parsed timestamp data from {}: {}".format(file_base_name, str(self.timestamp_data)))
        except ValueError:
            log.exception("Cannot parse date-like string {}. Defaulting to 'now'.".format(date_string))
        self.devices_data = {'camera': None}

    @property
    def timestamp(self):
        return self.timestamp_data

    @property
    def is_expired(self):
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        return now - self.timestamp_data > timedelta(seconds=self.validity_seconds)

    @property
    def data(self):
        return None

    @property
    def device_names(self):
        if self.devices_data is None:
            return None
        names = []
        for device_name in self.devices_data.keys():
            names.append(' '.join([self.source_label, device_name]))
        return names

    @property
    def devices(self):
        if self.devices_data is None:
            return {}
        return self.devices_data

    @property
    def source(self):
        return self.source_label

    def __str__(self):
        string = "{} at {}".format(self.source_label, self.timestamp.strftime('%X %x %Z'))
        if self.devices:
            return string + ": {} devices: {}".format(
                len(self.devices), ','.join(self.devices.keys()))
        return string


class CloudStorage(object):
    __metaclass__ = abc.ABCMeta

    @abc.abstractproperty
    def cloud_storage_url(self):
        return NotImplemented

    @abc.abstractmethod
    def upload(self, file_path, created_time):
        return NotImplemented


class GoogleDriveManager(Thread, CloudStorage):

    def __init__(self, gauth_creds_file, gdrive_folder):
        super(GoogleDriveManager, self).__init__()
        self.daemon = True

        self._gdrive_folder = gdrive_folder
        if '~' in gauth_creds_file:
            self._gauth_creds_file = os.path.expanduser(gauth_creds_file)
        else:
            self._gauth_creds_file = os.path.abspath(gauth_creds_file)
        self.drive = GoogleDrive(self.gauth)
        self._gdrive_folder_id, self._gdrive_folder_url = self._get_gdrive_folder_id(self.drive, gdrive_folder)
        # separate connection for archiver thread to prevent PyDrive lock-up
        self._archive_drive = GoogleDrive(self.gauth)
        self._folder_id_cache = {}
        self.mime = MimeTypes()

    @property
    def cloud_storage_url(self):
        return self._gdrive_folder_url

    def run(self):
        #TODO: remove
        sleep(5*60)
        while True:
            log.debug("Finding files in {} ({}) to archive.".format(self._gdrive_folder, self._gdrive_folder_id))
            file_list = self._archive_drive.ListFile({
                'q': "'{}' in parents and trashed=false and mimeType != 'application/vnd.google-apps.folder'".format(
                    self._gdrive_folder_id
                ),
                'maxResults': 100,
            })
            archived = 0
            try:
                while True:
                    page = file_list.GetList()
                    log.info('Inspecting {} files for archival...'.format(len(page)))
                    for file1 in page:
                        if self.archive(gdrive=self._archive_drive,
                                        gdrive_file=file1,
                                        root_folder_id=self._gdrive_folder_id):
                            archived += 1
            except StopIteration:
                log.info('Archived {} image snapshots.'.format(archived))
            # prevent memory leaks
            self._folder_id_cache.clear()
            # sleep until tomorrow
            sleep(60*60*24)

    @property
    def gauth(self):
        auth = GoogleAuth()
        if not os.path.exists(self._gauth_creds_file):
            log.debug("Google credentials not found in [{}]. Interactive setup may follow.".format(
                self._gauth_creds_file))
        # Try to load saved client credentials
        auth.LoadCredentialsFile(self._gauth_creds_file)
        if auth.credentials is None:
            # Authenticate if they're not there
            auth.LocalWebserverAuth()
        elif auth.access_token_expired:
            # Refresh them if expired
            auth.Refresh()
        else:
            # Initialize the saved creds
            auth.Authorize()
        if not os.path.exists(self._gauth_creds_file):
            # Save the current credentials to a file
            auth.SaveCredentialsFile(self._gauth_creds_file)
            log.debug("Saved Google credentials to {}".format(self._gauth_creds_file))
        return auth

    @staticmethod
    def _get_gdrive_folder_id(gdrive, gdrive_folder, parent_id='root', create=True):
        log.debug("Checking for existence of Google Drive folder '{}'".format(gdrive_folder))
        file_list = gdrive.ListFile({
            'q': "'{}' in parents and trashed=false and mimeType = 'application/vnd.google-apps.folder'"
            " and title = '{}'".format(parent_id, gdrive_folder)
        }).GetList()
        if len(file_list) == 0:
            if not create:
                return None
            log.debug("Creating Google Drive folder '{}' in parent folder '{}'".format(gdrive_folder, parent_id))
            folder = gdrive.CreateFile({
                'description': "Created by {}".format(APP), 'title': gdrive_folder,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [{"kind": "drive#parentReference", "id": parent_id}]
            })
            folder.Upload()
            folder_id = folder['id']
            folder_link = folder['alternateLink']
        elif len(file_list) == 1:
            folder_id = file_list[0]['id']
            folder_link = file_list[0]['alternateLink']
        else:
            raise RuntimeError("Unexpected result listing Google Drive for {}: {}".format(
                gdrive_folder, str(file_list)))
        log.debug("Google Drive folder ID for folder '{}' is '{}'. Visit at {}".format(
            gdrive_folder,
            folder_id,
            folder_link))
        return folder_id, folder_link

    def archive(self, gdrive, gdrive_file, root_folder_id):
        filename = gdrive_file['title']
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        created_date = dateutil.parser.parse(gdrive_file['createdDate'])
        td = now - created_date
        if td > timedelta(days=1):
            log.info('Archiving {} created {} days ago.'.format(filename, td.days))
            ymd_date = created_date.strftime('%Y-%m-%d')
            if ymd_date in self._folder_id_cache:
                gdrive_folder_id = self._folder_id_cache[ymd_date]
            else:
                # create the required folder structure
                year_folder_name = created_date.strftime('%Y')
                year_folder_id, url = self._get_gdrive_folder_id(gdrive, year_folder_name, root_folder_id)
                month_folder_name = created_date.strftime('%m')
                month_folder_id, url = self._get_gdrive_folder_id(gdrive, month_folder_name, year_folder_id)
                day_folder_name = created_date.strftime('%d')
                day_folder_id, url = self._get_gdrive_folder_id(gdrive, day_folder_name, month_folder_id)
                self._folder_id_cache[ymd_date] = day_folder_id
                gdrive_folder_id = day_folder_id
            log.debug('{} => folder key {} => folder ID {}'.format(filename, ymd_date, gdrive_folder_id))
            # reset the parent folders, include the existing parents if starred
            if gdrive_file['labels']['starred']:
                parents = []
                for parent in gdrive_file['parents']:
                    parent_id = parent['id']
                    parents.append(parent_id)
                    log.debug('Comparing parent {} with archive folder id {}'.format(parent_id, gdrive_folder_id))
                    if gdrive_folder_id == parent_id:
                        log.debug('{} already archived to {}'.format(filename, gdrive_folder_id))
                        return False
                log.info('Archiving starred file {}, but leaving existing parents intact.'.format(filename))
                # new parent for archival
                gdrive_parents = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
                # existing parents
                for parent in parents:
                    # simply appending the parents array returned by the service is insufficient
                    # possibly due to PyDrive's change detection, or Drive
                    gdrive_parents.append({"kind": "drive#parentReference", "id": parent})
                gdrive_file['parents'] = gdrive_parents
            else:
                # otherwise, clobber the existing parent information
                gdrive_file['parents'] = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
            # update the file metadata
            gdrive_file.Upload()
            return True
        return False

    def upload(self, file_path, created_time=None):
        # upload the snapshot
        mime_type = self.mime.guess_type(pathname2url(file_path))
        if mime_type is not None:
            mime_type = mime_type[0]
        log.info("'{}' file {}".format(mime_type, file_path))
        try:
            created_date = None
            if created_time is None:
                log.debug("Uploading '{}' to Google Drive".format(file_path))
            else:
                # datetime.isoformat doesn't work because of the seconds
                # separator required by RFC3339, and the extra requirement to have
                # the colon in the TZ offset if not in UTC.
                offset = created_time.strftime('%z')
                created_date = created_time.strftime('%Y-%m-%dT%H:%M:%S.00') + offset[:3] + ':' + offset[3:]
                log.debug("Uploading '{}' to Google Drive with created time of {}".format(file_path, created_date))

            f = self.drive.CreateFile({
                'title': os.path.basename(file_path),
                'mimeType': mime_type,
                'createdDate': created_date,
                'parents': [{"kind": "drive#fileLink", "id": self._gdrive_folder_id}]
            })
            f.SetContentFile(file_path)
            f.Upload()
            link = f['thumbnailLink']
            # specify our own thumbnail size
            if '=' in link:
                link = link.rsplit('=')[0]
                link += '=s1024'
            log.info("Uploaded '{}' to Google Drive folder '{}' (ID: '{}'). Thumbnail at {}".format(
                os.path.basename(file_path), self._gdrive_folder, f['id'], link))
        except FileNotUploadedError:
            log.exception("Cannot upload {} to Google Drive".format(file_path))


class UploadEventHandler(FileSystemEventHandler):

    def __init__(self, cloud_storage=None):
        super(UploadEventHandler, self).__init__()
        self.last_modified = None
        self._cloud_storage = cloud_storage
        self.sample_dirs = {}
        self.image_dirs = {}

    def add_sample_dir(self, source_label, sample_dir):
        if source_label in self.sample_dirs:
            raise RuntimeError("Sample source label {} is already configured.".format(source_label))
        self.sample_dirs[source_label] = sample_dir

    def _sample_dir_label(self, event_directory):
        for dir_label, sample_dir in self.sample_dirs.iteritems():
            if sample_dir in event_directory:
                return dir_label
        return None

    def add_image_dir(self, source_label, image_dir):
        if source_label in self.image_dirs:
            raise RuntimeError("Image source label {} is already configured.".format(source_label))
        self.image_dirs[source_label] = image_dir

    def _image_dir_label(self, event_directory):
        for dir_label, image_dir in self.image_dirs.iteritems():
            if image_dir in event_directory:
                return dir_label
        return None

    @property
    def watched_dirs(self):
        return self.sample_dirs.items() + self.image_dirs.items()

    # we listen to on-modified events because the file is
    # created and then written to subsequently.
    def on_modified(self, event):
        """
        :type event: FileModifiedEvent
        """
        super(UploadEventHandler, self).on_modified(event)
        # the file has been written to and has valid content
        if not event.is_directory:
            snapshot_path = event.src_path
            # de-duplication
            if snapshot_path != self.last_modified:
                self.last_modified = snapshot_path
            else:
                return
            # cross-check that we're in the right place
            if snapshot_path.startswith(snapshot_root):
                # noinspection PyBroadException
                try:
                    # sampled snapshot?
                    source_label = self._sample_dir_label(snapshot_path)
                    if source_label:
                        try:
                            snapshot = SampledSnapshot(
                                source_label=source_label,
                                file_path=snapshot_path,
                                validity_seconds=snapshot_validity_seconds)
                            log_msg = "Snapshot: {} from {}".format(snapshot, snapshot_path)
                            if len(snapshot.devices) > 0:
                                log.info(log_msg)
                            else:
                                log.debug(log_msg)
                            snapshot_queue.put(snapshot)
                            return
                        except UnpackException:
                            log.exception("Cannot unpack snapshot data in {}".format(snapshot_path))
                    # image snapshot?
                    source_label = self._image_dir_label(snapshot_path)
                    if source_label:
                        # create the snapshot data
                        snapshot = ImageSnapshot(
                            source_label=source_label,
                            file_path=snapshot_path,
                            validity_seconds=snapshot_validity_seconds)
                        log_msg = "Snapshot: {} from {}".format(snapshot, snapshot_path)
                        if len(snapshot.devices) > 0:
                            log.info(log_msg)
                        else:
                            log.debug(log_msg)
                        snapshot_queue.put(snapshot)
                        # upload the image snapshot
                        if self._cloud_storage:
                            self._cloud_storage.upload(
                                file_path=snapshot_path,
                                created_time=snapshot.timestamp)
                except Exception:
                    log.exception("Cannot process {}".format(snapshot_path))


class SMSEventHandler(Thread, FileSystemEventHandler):

    def __init__(self):
        super(SMSEventHandler, self).__init__()
        self.daemon = True

        balance_pattern = config.get('sms', 'balance_pattern')
        self.balance_pattern = re.compile(balance_pattern)
        sms_balance_pattern = config.get('sms', 'sms_balance_pattern')
        self.sms_balance_pattern = re.compile(sms_balance_pattern)
        log.debug("Matching SMS balance checks on patterns: '{}', '{}'".format(balance_pattern, sms_balance_pattern))
        self.sms_balance_check_number = config.get('sms', 'balance_check_number')
        self.sms_balance_check_message = config.get('sms', 'balance_check_message')
        self.balance_value_alert = float(config.get('sms', 'balance_value_alert'))
        self.sms_balance_value_alert = int(config.get('sms', 'sms_balance_value_alert'))

    def run(self):
        while True:
            log.info("Dispatching SMS balance enquiry '{}' to {}".format(
                self.sms_balance_check_message,
                self.sms_balance_check_number))
            notifier.send_sms(recipient=self.sms_balance_check_number, message=self.sms_balance_check_message)
            # sleep until later
            sleep(60*60*24)

    # we listen to on-modified events because the file is
    # created and then written to subsequently.
    def on_modified(self, event):
        """
        :type event: FileModifiedEvent
        """
        super(SMSEventHandler, self).on_modified(event)
        # the file has been written to and has valid content
        if not event.is_directory:
            log.info("Incoming SMS at {}".format(event.src_path))
            for line in open(event.src_path):
                # log the line
                log.info(line)
                balance_response = self.balance_pattern.search(line)
                topup_needed = False
                notification_message = ''
                if balance_response:
                    balance_value = float(balance_response.group(0))
                    if balance_value <= self.balance_value_alert:
                        warning = "Prepaid balance has reached {}. ".format(balance_value)
                        log.warn(warning)
                        notification_message += warning
                        topup_needed = True
                balance_response = self.sms_balance_pattern.search(line)
                if balance_response:
                    balance_value = int(balance_response.group(0))
                    if balance_value <= self.sms_balance_value_alert:
                        warning = "SMS balance has reached {}. ".format(balance_value)
                        log.warn(warning)
                        notification_message += warning
                        topup_needed = True
                if topup_needed:
                    notification_message += 'Top-up soon.'
                if len(notification_message) > 0:
                    notifier.notify_voice(message=notification_message, informational=True)
                else:
                    # something more generic
                    pass


class NetworkDeviceMonitor(Thread):

    def __init__(self):
        super(NetworkDeviceMonitor, self).__init__()
        self.daemon = True

        devices = config.get('network', 'device_macs').replace('-', ':').lower().split(',')
        owners = config.get('network', 'owners').split(',')
        self.owner_devices = dict(zip(owners, devices))
        self.ip_matcher = re.compile('((\d{1,3}\.){3}\d{1,3})')
        self.mac_matcher = re.compile('(([0-9a-f]{2}:){5}[0-9a-f]{2})')

    @staticmethod
    def exec_cmd(cmd):
        p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
        out, err = p.communicate()
        return out, p.returncode

    def run(self):
        while True:
            arp_cache = {}
            arp, rc = self.exec_cmd(['/usr/sbin/arp', '-an'])
            if rc != 0:
                log.debug("Problem collecting arp data.")
                sleep(60)
                continue
            for entry in arp.split('\n'):
                log.debug('Matching arp line {}'.format(entry))
                ip_m = self.ip_matcher.search(entry)
                if ip_m is None:
                    continue
                ip = ip_m.group(0)
                mac_m = self.mac_matcher.search(entry)
                if mac_m is None:
                    continue
                mac = mac_m.group(0)
                if mac not in arp_cache:
                    arp_cache[mac] = []
                arp_cache[mac].append(ip)
                log.debug('{} associated with IP {}'.format(mac, ip))
            log.debug("{} arp entries collected.".format(len(arp_cache)))
            for owner, device in self.owner_devices.iteritems():
                log.debug("Looking up {}'s device {}".format(owner, device))
                if device in arp_cache:
                    ips = arp_cache[device]
                    log.debug('{} owns device {} with IP candidate(s) {}'.format(owner, device, ips))
                    for ip in ips:
                        ping, rc = self.exec_cmd(['/bin/ping', '-c1', ip])
                        if rc == 0:
                            log.debug("{}'s device {} is present with IP {}".format(owner, device, ip))
                            arp_cache[device] = [ip]
                            break
                        else:
                            log.debug("{}'s device {} is not responding at IP {} right now.".format(owner, device, ip))
                else:
                    log.debug("{}'s device {} is not known to this network.".format(owner, device))
            sleep(60*60*12)


class SnapshotProcessor(Thread):

    def __init__(self):
        super(SnapshotProcessor, self).__init__()
        self.daemon = True

        self.last_snapshot = {}
        self.active_devices = {}
        self.latest_snapshot = datetime.utcnow().replace(tzinfo=pytz.utc)
        self.last_notification = 0

    def run(self):
        while True:
            snapshot = None
            try:
                snapshot = snapshot_queue.get(timeout=heartbeat_interval_seconds)
            except Empty:
                # deal with the heartbeat deficit below
                pass
            except Exception as e:
                log.error(e)
            else:
                snapshot_queue.task_done()

            if snapshot is not None:
                if snapshot.is_expired:
                    log.debug("Discarding expired snapshot {}".format(snapshot))
                    continue
                # only non-expired snapshots qualify as recent updates
                if snapshot.source is None:
                    #TODO: remove
                    log.debug('Processing snapshot without source? {}'.format(snapshot))
                self.last_snapshot[snapshot.source] = time.time()
                # throw away expired devices
                for device_name in self.active_devices.keys():
                    if datetime.utcnow().replace(tzinfo=pytz.utc) - self.active_devices[device_name] > timedelta(seconds=snapshot.validity_seconds):
                        del self.active_devices[device_name]
                # anything to process?
                if len(snapshot.devices) == 0:
                    continue
                # make a copy of the remaining, active devices
                old_device_names = self.active_devices.keys()
                # refresh the active devices
                for device_name in snapshot.device_names:
                    self.active_devices[device_name] = snapshot.timestamp
                # determine the new devices
                new_device_names = list(set(self.active_devices.keys()) - set(old_device_names))
                if len(self.active_devices) > 0 or len(new_device_names) > 0:
                    log.debug("{} active device(s), {} new.".format(len(self.active_devices), len(new_device_names)))
                last_notified = time.time() - self.last_notification
                # notify if the notification interval has elapsed or if there are new devices
                # and if the snapshot is newer than the last one for which a notification was sent
                if (last_notified > notification_interval_seconds or len(new_device_names) > 0) \
                        and self.latest_snapshot < snapshot.timestamp:
                    self.latest_snapshot = snapshot.timestamp
                    self.last_notification = time.time()
                    log.info("Sending notification for {}".format(str(new_device_names)))
                    for device_name in new_device_names:
                        notifier.notify_voice(message=device_name)
                        if isinstance(snapshot, ImageSnapshot):
                            #TODO: remove
                            recipient = notifier.sms_owners['Tai']
                            message = '{}: {}'.format(snapshot, cloud_storage.cloud_storage_url)
                            log.debug('SMS {} {} characters: {}'.format(recipient, len(message), message))
                            #TODO: fix
                            notifier.send_sms(recipient=recipient, message=message, flash=False)
            else:
                if snapshot.source not in self.last_snapshot:
                    self.last_snapshot[snapshot.source] = 0
                inactivity = time.time() - self.last_snapshot[snapshot.source]
                if inactivity > heartbeat_interval_seconds:
                    log.warn("A heartbeat or snapshot is overdue from {} (after {} seconds)".format(
                        snapshot.source,
                        heartbeat_interval_seconds))


def signal_handler(signum, frame):
    log.warn('Signal {} received, frame {}'.format(signum, str(frame)))
    log.debug('Draining deferred notifications now.')
    notifier.drain_deferred_notifications()

if __name__ == "__main__":
    # set up logging
    log.setLevel(logging.DEBUG)
    syslog_handler = logging.handlers.SysLogHandler(address='/dev/log')
    formatter = logging.Formatter('%(name)s [%(levelname)s] %(message)s')
    syslog_handler.setFormatter(formatter)
    log.addHandler(syslog_handler)
    stream_handler = logging.StreamHandler(stream=sys.stdout)
    log.addHandler(stream_handler)
    # set up config
    sample_labels = dict(config.items('sample_sources'))
    image_labels = dict(config.items('images_sources'))
    sample_snapshot_dirs = dict(config.items('sample_snapshot_dirs'))
    image_snapshot_dirs = dict(config.items('image_snapshot_dirs'))
    # set up signal handlers
    signal.signal(signal.SIGHUP, signal_handler)
    # remap the labels to the directories
    if len(sample_labels) != len(sample_snapshot_dirs) or len(image_labels) != len(image_snapshot_dirs):
        raise RuntimeError("Invalid configuration. Sources and associated labels must match.")
    # application threads
    notifier = Notifier()
    #network_device_monitor = NetworkDeviceMonitor()
    sms_event_handler = SMSEventHandler()
    processor = SnapshotProcessor()
    # ensure that auth is properly set up first
    google_drive = GoogleDriveManager(
        gauth_creds_file=config.get('gdrive', 'creds_file'),
        gdrive_folder=config.get('gdrive', 'folder'))
    cloud_storage = google_drive
    upload_event_handler = UploadEventHandler(cloud_storage=google_drive)
    # monitor these directories
    for source, label in sample_labels.iteritems():
        upload_event_handler.add_sample_dir(source_label=label, sample_dir=sample_snapshot_dirs[source])
    for source, label in image_labels.iteritems():
        upload_event_handler.add_image_dir(source_label=label, image_dir=image_snapshot_dirs[source])
    log.debug("Monitoring directories in {} for changes: {}".format(
        snapshot_root, str(upload_event_handler.watched_dirs)))
    # file system listener
    observer = Observer()
    observer.schedule(upload_event_handler, config.get('snapshots', 'root_dir'), recursive=True)
    observer.schedule(sms_event_handler, gammu_cfg.get('smsd', 'inboxpath'))
    observer.start()
    # start threads
    #network_device_monitor.start()
    sms_event_handler.start()
    processor.start()
    notifier.start()
    # start the Google Driver archiver last
    google_drive.start()
    try:
        while True:
            time.sleep(1)
    except(KeyboardInterrupt, SystemExit):
        log.info("Stopping threads...")
        observer.stop()
        log.info("Waiting for completion...")
        observer.join()
        log.info("Waiting for queue threads...")
        snapshot_queue.join()
        notifier.notification_queue.join()
        notifier.stop()
