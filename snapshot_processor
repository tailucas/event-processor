#!/usr/bin/python
import dateutil.parser
import hashlib
import logging
import logging.handlers

import os
import pytz
import re
import requests
import signal
import sys
import threading
import time
import umsgpack
import zmq

from ConfigParser import ConfigParser

import abc
import gammu.smsd
from clickatell.api import Clickatell
from clickatell.errors import ClickatellError
from clickatell import constants as cc
from datetime import datetime, timedelta
from dateutil import tz
from mimetypes import MimeTypes
from mplayer import Player
from pprint import pprint
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from pydrive.files import FileNotUploadedError
from sets import Set
from Queue import Queue, Empty
from threading import Thread, Timer
from time import sleep
from umsgpack import UnpackException
from urllib import pathname2url
from watchdog.events import FileSystemEventHandler, FileModifiedEvent
from watchdog.observers import Observer
from zmq import ContextTerminated
from flask import Flask

sys.displayhook = pprint

APP = os.path.basename(__file__)
DIR = os.path.abspath(os.path.dirname(__file__))
TTS_DIR = '/data/tts_samples'
# set the working directory for libraries that assume this (such as PyDrive)
os.chdir(DIR)
log = logging.getLogger(APP)

TTS_URL = 'http://translate.google.com/translate_tts'

config = ConfigParser()
config.optionxform = str
config.read([os.path.join(DIR, '{}.conf'.format(APP))])

snapshot_root = config.get('snapshots', 'root_dir')
heartbeat_interval_seconds = int(config.get('snapshots', 'heartbeat_interval_seconds'))
notification_interval_seconds = int(config.get('snapshots', 'notification_interval_seconds'))
snapshot_validity_seconds = int(config.get('snapshots', 'snapshot_validity_seconds'))

sms_recipient_names = config.get('sms', 'recipient_names').split(',')
sms_recipient_numbers = config.get('sms', 'recipient_numbers').split(',')
sms_owners = dict(zip(sms_recipient_names, sms_recipient_numbers))

cloud_storage = None

rest_api = Flask(APP)
zmq_context = zmq.Context()
URL_WORKER_NOTIFIER = 'inproc://notifier'
URL_WORKER_SNAPSHOT_PROCESSOR = 'inproc://snapshot-processor'


class FileType(object):

    def __init__(self):
        self.mime = MimeTypes()

    def mime_type(self, file_path):
        mime_type = self.mime.guess_type(pathname2url(file_path))
        if mime_type is not None and len(mime_type) > 0:
            return mime_type[0]
        return None

    def test_type(self, file_path, file_type):
        mime_type = self.mime_type(file_path)
        if mime_type is not None and mime_type.startswith('{}/'.format(file_type)):
            # return the specific file type
            return mime_type.split('/')[1]
        return None

filetype = None


class Notification(object):
    __metaclass__ = abc.ABCMeta

    def __init__(self, message):
        self.message = message

    def __str__(self):
        return self.message


class TTSNotification(Notification):

    def __init__(self, message, informational=False):
        super(TTSNotification, self).__init__(message=message)
        self.informational = informational

    @property
    def is_informational(self):
        return self.informational


class SMSNotification(Notification):

    def __init__(self, message, recipient, sender=None, flash=False):
        super(SMSNotification, self).__init__(message=message)
        self.recipient = recipient
        self.sender = sender
        self.flash = flash


class Notifier(Thread):

    def __init__(self, sms_provider):
        super(Notifier, self).__init__()
        self.name = self.__class__.__name__
        self.daemon = True

        self.player = None

        self.sms_provider = sms_provider

        self.socket = zmq_context.socket(zmq.PULL)
        self.socket.bind(URL_WORKER_NOTIFIER)

        self.notification_timer = None
        self.deferred_notifications = Queue()

        self.tts_default_sound_file = config.get('app', 'tts_default_sound')

        not_before = config.get('informational_notifications', 'not_before')
        if not_before:
            self.informational_not_before = dateutil.parser.parse(not_before)
        not_after = config.get('informational_notifications', 'not_after')
        if not_after:
            self.informational_not_after = dateutil.parser.parse(not_after)
        self.any_time = False
        if not_before is None or not_after is None:
            self.any_time = True
        else:
            log.info('Informational notifications after {} will be deferred until {}.'.format(
                not_after,
                not_before))

    def run(self):
        # black-holding STDOUT causes properties to not work
        self.player = Player(stderr=open('/dev/null', 'w'), autospawn=True)
        while True:
            notification = None
            try:
                notification = self.socket.recv_pyobj()
            except ContextTerminated:
                break
            except Exception:
                log.exception(self.__class__.__name__)
                continue
            if isinstance(notification, TTSNotification):
                try:
                    self.say(str(notification))
                except StandardError:
                    log.exception("Unable to say message: '{}'".format(notification))
                    self.play_file(os.path.join(TTS_DIR, self.tts_default_sound_file))
            elif isinstance(notification, SMSNotification):
                self.send_sms(recipient=notification.recipient,
                              message=notification.message,
                              flash=notification.flash)
            else:
                log.error('Unknown notification type {}'.format(notification.__class__))

    def stop(self):
        if self.player:
            self.player.quit()

    def play_file(self, sound_file):
        if self.player:
            self.player.loadfile(sound_file)
            try:
                delay = int(self.player.length)
                # block for the duration of this audio sample
                log.debug("Playing '{}' for {}s".format(sound_file, delay))
                sleep(delay)
            except TypeError:
                log.warn("Playing '{}' without block because no player length was provided.".format(sound_file))
                pass
        else:
            log.error("No player loaded to play '{}'".format(sound_file))

    def say(self, message):
        msg_checksum = Notifier.checksum(message)
        log.debug("Checksum for '{}' is [{}]".format(message, msg_checksum))
        tts_file = '{}.mp3'.format(msg_checksum)
        tts_path = os.path.join(TTS_DIR, tts_file)
        if os.path.isfile(tts_path) and os.path.getsize(tts_path) == 0:
            log.debug('Removing empty file {}'.format(tts_path))
            os.remove(tts_path)
        if filetype.test_type(tts_path, 'audio') is None:
            log.debug('Removing audio file of unknown type {}'.format(tts_path))
            os.remove(tts_path)
        log.debug('{} exists? {}'.format(tts_path, os.path.isfile(tts_path)))
        if not os.path.isfile(tts_path):
            log.debug("Generating '{}' using {}".format(message, TTS_URL))
            r = requests.get(
                url=TTS_URL,
                # http://stackoverflow.com/questions/9893175/google-text-to-speech-api
                # curl 'http://translate.google.com/translate_tts?ie=UTF-8&q=Hello&tl=en&client=t'
                # -H 'Referer: http://translate.google.com/' -H 'User-Agent: stagefright/1.2 (Linux;Android 5.0)' > google_tts.mp3
                params={'ie': 'UTF-8',
                        'tl': 'en',
                        'client': 't',
                        'q': message},
                headers={'User-Agent': 'stagefright/1.2 (Linux;Android 5.0)',
                         'Referer': 'http://translate.google.com/'},
                allow_redirects=False)
            log.debug('HTTP {} from {}'.format(r.status_code, r.url))
            r.raise_for_status()
            log.debug('HTTP response: {}'.format(r.headers))
            # HTTP30x
            if r.status_code >= 300 and r.status_code < 400:
                # try to give some helpful information
                if 'location' in r.headers:
                    log.warning('You must visit {} to create {}'.format(r.headers['location'], tts_path))
            if r.status_code == requests.codes.ok:
                # only write a file upon success
                with open(tts_path, 'wb') as fd:
                    for chunk in r.iter_content(1024*64):
                        fd.write(chunk)
                log.debug('Written {} bytes to {}'.format(os.path.getsize(tts_path), tts_path))
        if os.path.isfile(tts_path):
            # now play
            log.debug("Saying '{}'...".format(message))
            self.play_file(tts_path)
        else:
            raise StandardError('No file {} to play "{}"'.format(tts_path, message))

    def drain_deferred_notifications(self):
        # cancel the timer in case we're signalled instead
        self.notification_timer.cancel()
        log.info('Draining {} notifications deferred until now.'.format(self.deferred_notifications.qsize()))
        while not self.deferred_notifications.empty():
            try:
                pass
                #TODO: fix
                #self.notification_queue.put(self.deferred_notifications.get())
            except Exception as e:
                log.error(e)
            else:
                self.deferred_notifications.task_done()
        # Delete the expired the timer
        self.notification_timer = None

    def notify_voice(self, message, informational=False):
        #TODO: remove
        informational=False
        if not informational or self.any_time:
            self.notification_queue.put(message)
        else:
            # make a future date that is relative (after) now time.
            now = datetime.now().replace(tzinfo=tz.tzlocal())
            not_before = now.replace(
                hour=self.informational_not_before.hour,
                minute=self.informational_not_before.minute,
                second=0,
                microsecond=0)
            not_after = now.replace(
                hour=self.informational_not_after.hour,
                minute=self.informational_not_after.minute,
                second=0,
                microsecond=0)
            log.debug("Comparing now {} with 'not_after' of {}".format(now, not_after))
            if now < not_after:
                # go ahead
                log.debug('No notification deferral necessary.')
                self.notification_queue.put(message)
                return
            elif now >= not_after:
                # the not-before time may not be on the same day
                if now > not_before:
                    defer_until = not_before + timedelta(days=1)
            else:
                defer_until = not_before
            # defer the notification
            log.info("Deferring informational notification '{}' until {}".format(message, defer_until))
            self.deferred_notifications.put(message)
            if self.notification_timer is None:
                # now calculate the sleep time based on the deferral
                delay = defer_until - now
                log.debug('Deferring notifications for {} hours.'.format(delay.seconds / 3600))
                self.notification_timer = Timer(delay.seconds, self.drain_deferred_notifications)

    def send_sms(self, recipient, message, flash=False):
        self.sms_provider.send_sms(recipient=recipient, message=message, flash=flash)

    @staticmethod
    def checksum(message):
        m = hashlib.md5()
        m.update(message)
        return m.hexdigest()


class Snapshot(object):
    __metaclass__ = abc.ABCMeta

    def __init__(self, validity_seconds):
        self.validity_seconds = validity_seconds

    @abc.abstractproperty
    def timestamp(self):
        return NotImplemented

    @abc.abstractproperty
    def is_expired(self):
        return NotImplemented

    @abc.abstractproperty
    def data(self):
        return NotImplemented

    @abc.abstractproperty
    def device_names(self):
        return NotImplemented

    @abc.abstractproperty
    def devices(self):
        return NotImplemented

    @abc.abstractproperty
    def source(self):
        return NotImplemented


class SampledSnapshot(Snapshot):

    def __init__(self, snapshot_data, validity_seconds):
        super(SampledSnapshot, self).__init__(validity_seconds=validity_seconds)
        self.snapshot_data = snapshot_data
        self.source_label = None
        if 'location' in self.snapshot_data:
            self.source_label = self.snapshot_data['location']
        self.timestamp_data = dateutil.parser.parse(self.snapshot_data['timestamp'])
        if self.timestamp_data.tzinfo is None:
            # we use the phyiscal locality of this device for timezone
            self.timestamp_data = self.timestamp_data.replace(tzinfo=tz.tzlocal())
        if 'data' in self.snapshot_data:
            if 'samples' in self.snapshot_data['data']:
                self.devices_data = self.snapshot_data['data']['samples']
            else:
                self.devices_data = None
            if 'devices_nearby' in self.snapshot_data['data']:
                self.devices_nearby = self.snapshot_data['data']['devices_nearby']
            else:
                self.devices_nearby = None
        else:
            self.devices_data = self.devices_nearby = None

    @property
    def timestamp(self):
        return self.timestamp_data

    @property
    def is_expired(self):
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        return now - self.timestamp_data > timedelta(seconds=self.validity_seconds)

    @property
    def data(self):
        return self.snapshot_data

    @property
    def device_names(self):
        names = list()
        if self.devices_data is not None:
            for device_name in self.devices_data.keys():
                if self.source_label:
                    names.append(' '.join([self.source_label, device_name]))
                else:
                    names.append(device_name)
        if self.devices_nearby is not None:
            for device_name in self.devices_nearby.keys():
                names.append('{} is here'.format(device_name))
        if len(names) > 0:
            return names
        return None

    @property
    def devices(self):
        devices = dict()
        if self.devices_data is not None:
            devices.update(self.devices_data)
        if self.devices_nearby is not None:
            devices.update(self.devices_nearby)
        return devices

    @property
    def source(self):
        return self.source_label

    def __str__(self):
        string = 'At {}'.format(self.timestamp.strftime('%X %x %Z'))
        if self.source_label:
            string = '{} at {}'.format(self.source_label, self.timestamp.strftime('%X %x %Z'))
        if self.devices:
            return string + ': {} devices: {}'.format(
                len(self.devices), ','.join(self.devices.keys()))
        return string


class ImageSnapshot(Snapshot):

    def __init__(self, source_label, file_path, validity_seconds):
        super(ImageSnapshot, self).__init__(validity_seconds=validity_seconds)
        # default timestamp data to 'now'
        self.source_label = source_label
        self.timestamp_data = datetime.utcnow().replace(tzinfo=pytz.utc)
        try:
            file_base_name = os.path.splitext(os.path.basename(file_path))[0]
            if '_' in file_base_name:
                date_string = file_base_name.split('_')[1]
            else:
                date_string = file_base_name
            self.timestamp_data = dateutil.parser.parse(date_string)
            if self.timestamp_data.tzinfo is None:
                # we use the default specific to the physical locality of the devices
                self.timestamp_data = self.timestamp_data.replace(tzinfo=tz.tzlocal())
            log.debug('Parsed timestamp data from {}: {}'.format(file_base_name, str(self.timestamp_data)))
        except ValueError:
            log.exception("Cannot parse date-like string {}. Defaulting to 'now'.".format(date_string))
        self.devices_data = {'camera': None}

    @property
    def timestamp(self):
        return self.timestamp_data

    @property
    def is_expired(self):
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        return now - self.timestamp_data > timedelta(seconds=self.validity_seconds)

    @property
    def data(self):
        return None

    @property
    def device_names(self):
        if self.devices_data is None:
            return None
        names = list()
        for device_name in self.devices_data.keys():
            names.append(' '.join([self.source_label, device_name]))
        return names

    @property
    def devices(self):
        if self.devices_data is None:
            return {}
        return self.devices_data

    @property
    def source(self):
        return self.source_label

    def __str__(self):
        string = '{} at {}'.format(self.source_label, self.timestamp.strftime('%X %x %Z'))
        if self.devices:
            return string + ': {} devices: {}'.format(
                len(self.devices), ','.join(self.devices.keys()))
        return string


class CloudStorage(object):
    __metaclass__ = abc.ABCMeta

    @abc.abstractproperty
    def cloud_storage_url(self):
        return NotImplemented

    @abc.abstractmethod
    def upload(self, file_path, created_time):
        return NotImplemented


class GoogleDriveManager(Thread, CloudStorage):

    def __init__(self, gauth_creds_file, gdrive_folder):
        super(GoogleDriveManager, self).__init__()
        self.name = self.__class__.__name__
        self.daemon = True

        self._gdrive_folder = gdrive_folder
        if '~' in gauth_creds_file:
            self._gauth_creds_file = os.path.expanduser(gauth_creds_file)
        else:
            self._gauth_creds_file = os.path.abspath(gauth_creds_file)
        self.drive = GoogleDrive(self.gauth)
        self._gdrive_folder_id, self._gdrive_folder_url = self._get_gdrive_folder_id(self.drive, gdrive_folder)
        # separate connection for archiver thread to prevent PyDrive lock-up
        self._archive_drive = GoogleDrive(self.gauth)
        self._folder_id_cache = dict()

    @property
    def cloud_storage_url(self):
        return self._gdrive_folder_url

    def run(self):
        #TODO: remove
        sleep(5*60)
        while True:
            log.debug('Finding files in {} ({}) to archive.'.format(self._gdrive_folder, self._gdrive_folder_id))
            file_list = self._archive_drive.ListFile({
                'q': "'{}' in parents and trashed=false and mimeType != 'application/vnd.google-apps.folder'".format(
                    self._gdrive_folder_id
                ),
                'maxResults': 100,
            })
            archived = 0
            try:
                while True:
                    page = file_list.GetList()
                    log.info('Inspecting {} files for archival...'.format(len(page)))
                    for file1 in page:
                        if self.archive(gdrive=self._archive_drive,
                                        gdrive_file=file1,
                                        root_folder_id=self._gdrive_folder_id):
                            archived += 1
            except StopIteration:
                log.info('Archived {} image snapshots.'.format(archived))
            # prevent memory leaks
            self._folder_id_cache.clear()
            # sleep until tomorrow
            sleep(60*60*24)

    @property
    def gauth(self):
        auth = GoogleAuth()
        if not os.path.exists(self._gauth_creds_file):
            log.debug('Google credentials not found in [{}]. Interactive setup may follow.'.format(
                self._gauth_creds_file))
        # Try to load saved client credentials
        auth.LoadCredentialsFile(self._gauth_creds_file)
        if auth.credentials is None:
            # Authenticate if they're not there
            auth.LocalWebserverAuth()
        elif auth.access_token_expired:
            # Refresh them if expired
            auth.Refresh()
        else:
            # Initialize the saved creds
            auth.Authorize()
        if not os.path.exists(self._gauth_creds_file):
            # Save the current credentials to a file
            auth.SaveCredentialsFile(self._gauth_creds_file)
            log.debug('Saved Google credentials to {}'.format(self._gauth_creds_file))
        return auth

    @staticmethod
    def _get_gdrive_folder_id(gdrive, gdrive_folder, parent_id='root', create=True):
        log.debug("Checking for existence of Google Drive folder '{}'".format(gdrive_folder))
        file_list = gdrive.ListFile({
            'q': "'{}' in parents and trashed=false and mimeType = 'application/vnd.google-apps.folder'"
            " and title = '{}'".format(parent_id, gdrive_folder)
        }).GetList()
        if len(file_list) == 0:
            if not create:
                return None
            log.debug("Creating Google Drive folder '{}' in parent folder '{}'".format(gdrive_folder, parent_id))
            folder = gdrive.CreateFile({
                'description': "Created by {}".format(APP), 'title': gdrive_folder,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [{"kind": "drive#parentReference", "id": parent_id}]
            })
            folder.Upload()
            folder_id = folder['id']
            folder_link = folder['alternateLink']
        elif len(file_list) == 1:
            folder_id = file_list[0]['id']
            folder_link = file_list[0]['alternateLink']
        else:
            raise RuntimeError('Unexpected result listing Google Drive for {}: {}'.format(
                gdrive_folder, str(file_list)))
        log.debug("Google Drive folder ID for folder '{}' is '{}'. Visit at {}".format(
            gdrive_folder,
            folder_id,
            folder_link))
        return folder_id, folder_link

    def archive(self, gdrive, gdrive_file, root_folder_id):
        filename = gdrive_file['title']
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        created_date = dateutil.parser.parse(gdrive_file['createdDate'])
        td = now - created_date
        if td > timedelta(days=1):
            log.info('Archiving {} created {} days ago.'.format(filename, td.days))
            ymd_date = created_date.strftime('%Y-%m-%d')
            if ymd_date in self._folder_id_cache:
                gdrive_folder_id = self._folder_id_cache[ymd_date]
            else:
                # create the required folder structure
                year_folder_name = created_date.strftime('%Y')
                year_folder_id, url = self._get_gdrive_folder_id(gdrive, year_folder_name, root_folder_id)
                month_folder_name = created_date.strftime('%m')
                month_folder_id, url = self._get_gdrive_folder_id(gdrive, month_folder_name, year_folder_id)
                day_folder_name = created_date.strftime('%d')
                day_folder_id, url = self._get_gdrive_folder_id(gdrive, day_folder_name, month_folder_id)
                self._folder_id_cache[ymd_date] = day_folder_id
                gdrive_folder_id = day_folder_id
            log.debug('{} => folder key {} => folder ID {}'.format(filename, ymd_date, gdrive_folder_id))
            # reset the parent folders, include the existing parents if starred
            if gdrive_file['labels']['starred']:
                parents = list()
                for parent in gdrive_file['parents']:
                    parent_id = parent['id']
                    parents.append(parent_id)
                    log.debug('Comparing parent {} with archive folder id {}'.format(parent_id, gdrive_folder_id))
                    if gdrive_folder_id == parent_id:
                        log.debug('{} already archived to {}'.format(filename, gdrive_folder_id))
                        return False
                log.info('Archiving starred file {}, but leaving existing parents intact.'.format(filename))
                # new parent for archival
                gdrive_parents = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
                # existing parents
                for parent in parents:
                    # simply appending the parents array returned by the service is insufficient
                    # possibly due to PyDrive's change detection, or Drive
                    gdrive_parents.append({"kind": "drive#parentReference", "id": parent})
                gdrive_file['parents'] = gdrive_parents
            else:
                # otherwise, clobber the existing parent information
                gdrive_file['parents'] = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
            # update the file metadata
            gdrive_file.Upload()
            return True
        return False

    def upload(self, file_path, created_time=None):
        # upload the snapshot
        mime_type = filetype.mime_type(file_path)
        log.info("'{}' file {}".format(mime_type, file_path))
        try:
            created_date = None
            if created_time is None:
                log.debug("Uploading '{}' to Google Drive".format(file_path))
            else:
                # datetime.isoformat doesn't work because of the seconds
                # separator required by RFC3339, and the extra requirement to have
                # the colon in the TZ offset if not in UTC.
                offset = created_time.strftime('%z')
                created_date = created_time.strftime('%Y-%m-%dT%H:%M:%S.00') + offset[:3] + ':' + offset[3:]
                log.debug("Uploading '{}' to Google Drive with created time of {}".format(file_path, created_date))

            f = self.drive.CreateFile({
                'title': os.path.basename(file_path),
                'mimeType': mime_type,
                'createdDate': created_date,
                'parents': [{"kind": "drive#fileLink", "id": self._gdrive_folder_id}]
            })
            f.SetContentFile(file_path)
            f.Upload()
            link_msg = ""
            if 'thumbnailLink'in f:
                link = f['thumbnailLink']
                # specify our own thumbnail size
                if '=' in link:
                    link = link.rsplit('=')[0]
                    link += '=s1024'
                link_msg = " Thumbnail at {}".format(link)
            log.info("Uploaded '{}' to Google Drive folder '{}' (ID: '{}').{}".format(
                    os.path.basename(file_path), self._gdrive_folder, f['id'], link_msg))
        except FileNotUploadedError:
            log.exception('Cannot upload {} to Google Drive'.format(file_path))


class UploadEventHandler(FileSystemEventHandler):

    def __init__(self, cloud_storage=None):
        super(UploadEventHandler, self).__init__()
        self.last_modified = None
        self._cloud_storage = cloud_storage
        self.image_dirs = dict()

        self.processor = zmq_context.socket(zmq.PUSH)
        self.processor.connect(URL_WORKER_SNAPSHOT_PROCESSOR)

    def add_image_dir(self, source_label, image_dir):
        if source_label in self.image_dirs:
            raise RuntimeError('Image source label {} is already configured.'.format(source_label))
        self.image_dirs[source_label] = image_dir

    def _image_dir_label(self, event_directory):
        for dir_label, image_dir in self.image_dirs.iteritems():
            if image_dir in event_directory:
                return dir_label
        return None

    @property
    def watched_dirs(self):
        return self.image_dirs.items()

    # we listen to on-modified events because the file is
    # created and then written to subsequently.
    def on_modified(self, event):
        """
        :type event: FileModifiedEvent
        """
        super(UploadEventHandler, self).on_modified(event)
        # the file has been written to and has valid content
        if not event.is_directory:
            snapshot_path = event.src_path
            # de-duplication
            if snapshot_path != self.last_modified:
                self.last_modified = snapshot_path
            else:
                return
            # cross-check that we're in the right place
            if snapshot_path.startswith(snapshot_root):
                # noinspection PyBroadException
                try:
                    # image snapshot?
                    source_label = self._image_dir_label(snapshot_path)
                    if source_label:
                        # create the snapshot data
                        snapshot = ImageSnapshot(
                            source_label=source_label,
                            file_path=snapshot_path,
                            validity_seconds=snapshot_validity_seconds)
                        log.info('Snapshot: {} from {}'.format(snapshot, snapshot_path))
                        self.processor.send_pyobj(snapshot)
                        # upload the image snapshot
                        if self._cloud_storage:
                            self._cloud_storage.upload(
                                file_path=snapshot_path,
                                created_time=snapshot.timestamp)
                except Exception:
                    log.exception('Cannot process {}'.format(snapshot_path))


class SampledSnapshotEventHandler(Thread):

    def __init__(self, publisher_endpoint):
        super(SampledSnapshotEventHandler, self).__init__()
        self.name = '{}::{}'.format(self.__class__.__name__, publisher_endpoint)
        self.daemon = True

        self._publisher_endpoint = publisher_endpoint

        self.subscriber = zmq_context.socket(zmq.SUB)

        self.processor = zmq_context.socket(zmq.PUSH)

        self.last_snapshot = dict()
        self.active_devices = dict()
        self.latest_snapshot = datetime.utcnow().replace(tzinfo=pytz.utc)
        self.last_notification = 0

    def run(self):
        log.info('Connecting event subscriber to {}'.format(self._publisher_endpoint))
        self.subscriber.connect(self._publisher_endpoint)
        self.subscriber.setsockopt(zmq.SUBSCRIBE, "")
        self.processor.connect(URL_WORKER_SNAPSHOT_PROCESSOR)
        while True:
            try:
                snapshot_data = umsgpack.unpackb(self.subscriber.recv())
            except UnpackException:
                log.exception('Cannot unpack sampled snapshot data.')
                continue
            except ContextTerminated:
                break
            snapshot = SampledSnapshot(
                snapshot_data=snapshot_data,
                validity_seconds=snapshot_validity_seconds)
            log.debug('Snapshot: {} from {}'.format(snapshot, self._publisher_endpoint))
            self.processor.send_pyobj(snapshot)


class SMSProvider(object):
    __metaclass__ = abc.ABCMeta

    @abc.abstractmethod
    def send_sms(self, recipient, message, flash):
        return NotImplemented


class GammuSMSProvider(Thread, FileSystemEventHandler, SMSProvider):

    def __init__(self):
        super(GammuSMSProvider, self).__init__()
        self.name = self.__class__.__name__
        self.daemon = True

        gammu_cfg_file = config.get('sms', 'gammu-smsdrc')
        self.smsd = gammu.smsd.SMSD(gammu_cfg_file)
        gammu_cfg = ConfigParser()
        gammu_cfg.optionxform = str
        gammu_cfg.read(gammu_cfg_file)

        balance_pattern = config.get('gammu', 'balance_pattern')
        self.balance_pattern = re.compile(balance_pattern)
        sms_balance_pattern = config.get('gammu', 'sms_balance_pattern')
        self.sms_balance_pattern = re.compile(sms_balance_pattern)
        log.debug("Matching SMS balance checks on patterns: '{}', '{}'".format(balance_pattern, sms_balance_pattern))
        self.sms_balance_check_number = config.get('gammu', 'balance_check_number')
        self.sms_balance_check_message = config.get('gammu', 'balance_check_message')
        self.balance_value_alert = float(config.get('gammu', 'balance_value_alert'))
        self.sms_balance_value_alert = int(config.get('gammu', 'sms_balance_value_alert'))

        self.inbox_path = gammu_cfg.get('smsd', 'inboxpath')
        self.error_path = gammu_cfg.get('smsd', 'errorsmspath')

    @property
    def spool_directories(self):
        return (self.inbox_path, self.error_path)

    def send_sms(self, recipient, message, flash):
        sms_class = 1
        if flash:
            sms_class = 0
        message = {
            'Text': message,
            'SMSC': {'Location': 1},
            'Number': recipient,
            'Class': sms_class
        }
        self.smsd.InjectSMS([message])

    def run(self):
        while True:
            log.info("Dispatching SMS balance enquiry '{}' to {}".format(
                self.sms_balance_check_message,
                self.sms_balance_check_number))
            self.send_sms(recipient=self.sms_balance_check_number, message=self.sms_balance_check_message, flash=False)
            # sleep until later
            sleep(60*60*24)

    # we listen to on-modified events because the file is
    # created and then written to subsequently.
    def on_modified(self, event):
        """
        :type event: FileModifiedEvent
        """
        super(GammuSMSProvider, self).on_modified(event)
        # the file has been written to and has valid content
        if not event.is_directory:
            if self.inbox_path in event.src_path:
                log.info('Incoming SMS at {}'.format(event.src_path))
                for line in open(event.src_path):
                    # log the line
                    log.info(line)
                    balance_response = self.balance_pattern.search(line)
                    topup_needed = False
                    notification_message = ''
                    if balance_response:
                        balance_value = float(balance_response.group(0))
                        if balance_value <= self.balance_value_alert:
                            log.warn('Prepaid balance has reached {}. '.format(balance_value))
                            notification_message += "Prepaid balance is running low. "
                            topup_needed = True
                    balance_response = self.sms_balance_pattern.search(line)
                    if balance_response:
                        balance_value = int(balance_response.group(0))
                        if balance_value <= self.sms_balance_value_alert:
                            log.warn('SMS balance has reached {}. '.format(balance_value))
                            notification_message += "SMS balance is running low. "
                            topup_needed = True
                    if topup_needed:
                        notification_message += 'Top-up soon.'
                    if len(notification_message) > 0:
                        notifier.notify_voice(message=notification_message, informational=True)
                    else:
                        # something more generic
                        pass
            elif self.error_path in event.src_path:
                log.warn('SMS error at {}'.format(event.src_path))
                notifier.notify_voice(message="SMS fault!", informational=True)
            else:
                log.warn('Unsupported SMS event path: {}'.format(event.src_path))
                # some other path that is unsupported
                pass


class ClickatellSMSProvider(SMSProvider):

    def __init__(self):
        super(ClickatellSMSProvider, self).__init__()
        user = config.get('clickatell', 'user')
        password = config.get('clickatell', 'password')
        app_id = config.get('clickatell', 'app-id')
        self.clickatell = Clickatell(user, password, app_id)

    def send_sms(self, recipient, message, flash):
        try:
            [resp] = self.clickatell.sendmsg(recipients=[recipient], text=message)
            log.debug('SMS sent: {}'.format(str(resp)))
        except ClickatellError:
            log.exception('Cannot SMS {}: {}'.format(recipient, message))


class SnapshotProcessor(Thread):

    def __init__(self):
        super(SnapshotProcessor, self).__init__()
        self.name = self.__class__.__name__
        self.daemon = True

        self.notifier = zmq_context.socket(zmq.PUSH)

        self.relay_control = zmq_context.socket(zmq.PUSH)

        self.socket = zmq_context.socket(zmq.PULL)
        self.socket.bind(URL_WORKER_SNAPSHOT_PROCESSOR)

        self.active_devices = dict()
        self.latest_snapshot = datetime.utcnow().replace(tzinfo=pytz.utc)
        self.last_notification = 0

    def run(self):
        self.notifier.connect(URL_WORKER_NOTIFIER)
        relay_control_endpoint = config.get('zmq', 'relay_control')
        log.info('Relay control is at {}'.format(relay_control_endpoint))
        self.relay_control.connect(relay_control_endpoint)
        while True:
            try:
                snapshot = self.socket.recv_pyobj()
            except ContextTerminated:
                break
            except Exception:
                log.exception(self.__class__.__name__)
                continue
            log_msg = 'Processing: {}'.format(snapshot)
            if len(snapshot.devices) > 0:
                log.info(log_msg)
            else:
                log.debug(log_msg)
            if snapshot.is_expired:
                log.debug('Discarding expired snapshot {}'.format(snapshot))
                continue
            # only non-expired snapshots qualify as recent updates
            # throw away expired devices
            for device_name in self.active_devices.keys():
                if datetime.utcnow().replace(tzinfo=pytz.utc) - self.active_devices[device_name] > timedelta(seconds=snapshot.validity_seconds):
                    del self.active_devices[device_name]
            # anything to process?
            if len(snapshot.devices) == 0:
                continue
            # make a copy of the remaining, active devices
            old_device_names = self.active_devices.keys()
            # refresh the active devices
            for device_name in snapshot.device_names:
                self.active_devices[device_name] = snapshot.timestamp
            # determine the new devices
            new_device_names = list(set(self.active_devices.keys()) - set(old_device_names))
            if len(self.active_devices) > 0 or len(new_device_names) > 0:
                log.debug('{} active device(s) ({}), {} new ({}).'.format(
                    len(self.active_devices),
                    ','.join(self.active_devices.keys()),
                    len(new_device_names),
                    ','.join(new_device_names)))
            last_notified = time.time() - self.last_notification
            # notify if the notification interval has elapsed or if there are new devices
            # and if the snapshot is newer than the last one for which a notification was sent
            if (last_notified > notification_interval_seconds or len(new_device_names) > 0) \
                    and self.latest_snapshot < snapshot.timestamp:
                log.debug('Setting latest snapshot [{}] to [{}] from {} ({})'.format(
                    self.latest_snapshot,
                    snapshot.timestamp,
                    snapshot.device_names,
                    snapshot))
                self.latest_snapshot = snapshot.timestamp
                self.last_notification = time.time()
                log.info('Sending notification for {}'.format(str(new_device_names)))
                for device_name in new_device_names:
                    self.notifier.send_pyobj(TTSNotification(message=device_name))
                    if isinstance(snapshot, ImageSnapshot):
                        for name, recipient in sms_owners.items():
                            message = '{}: {}'.format(snapshot, cloud_storage.cloud_storage_url)
                            log.info('Send SMS {} ({}) {} characters: {}'.format(name, recipient, len(message), message))
                            self.notifier.send_pyobj(SMSNotification(message=message, recipient=recipient, flash=False))
                    #FIXME
                    relays = 4
                    relay_activations = dict()
                    for i in range(1, relays+1):
                        relay_activations['relay{}'.format(i)] = {'state': True, 'delay': 5+i}
                    payload = dict()
                    payload['relays'] = relay_activations
                    log.info("Sending relay control: '{}'".format(payload))
                    self.relay_control.send(umsgpack.packb(payload))
            else:
                log.debug("Not notifying yet, last notified: [{}], latest snapshot: [{}], current snapshot: [{}]".format(
                    last_notified,
                    self.latest_snapshot,
                    snapshot.timestamp))


def signal_handler(signum, frame):
    log.warn('Signal {} received.'.format(signum))
    log.setLevel(logging.DEBUG)
    log.debug('Draining deferred notifications now.')
    notifier.drain_deferred_notifications()


@rest_api.route('/')
def rest_index():
    notifier.play_file(os.path.join(TTS_DIR, config.get('app', 'tts_startup_sound')))
    return 'hello'


if __name__ == "__main__":
    # set up logging
    log.setLevel(logging.INFO)
    syslog_handler = logging.handlers.SysLogHandler(address='/dev/log')
    formatter = logging.Formatter('%(name)s [%(levelname)s] %(message)s')
    syslog_handler.setFormatter(formatter)
    log.addHandler(syslog_handler)
    if sys.stdout.isatty():
        stream_handler = logging.StreamHandler(stream=sys.stdout)
        log.addHandler(stream_handler)
    # set up config
    image_labels = dict(config.items('images_sources'))
    image_snapshot_dirs = dict(config.items('image_snapshot_dirs'))
    # set up signal handlers
    signal.signal(signal.SIGHUP, signal_handler)
    # remap the labels to the directories
    if len(image_labels) != len(image_snapshot_dirs):
        raise RuntimeError('Invalid configuration. Sources and associated labels must match.')
    # top-level types
    filetype = FileType()
    # sms
    sms_method = config.get('sms', 'method')
    if sms_method == 'gammu':
        sms_provider = GammuSMSProvider()
    elif sms_method == 'clickatell':
        sms_provider = ClickatellSMSProvider()
    else:
        raise RuntimeError('Unknown SMS method specified: {}'.format(sms_method))
    # application threads
    notifier = Notifier(sms_provider=sms_provider)
    processor = SnapshotProcessor()
    # sampled snapshot processing
    sample_event_handler = SampledSnapshotEventHandler(publisher_endpoint=config.get('zmq', 'sample_publisher'))
    detector_event_handler = SampledSnapshotEventHandler(publisher_endpoint=config.get('zmq', 'detector_publisher'))
    # ensure that auth is properly set up first
    google_drive = GoogleDriveManager(
        gauth_creds_file=config.get('gdrive', 'creds_file'),
        gdrive_folder=config.get('gdrive', 'folder'))
    cloud_storage = google_drive
    upload_event_handler = UploadEventHandler(cloud_storage=google_drive)
    # monitor these directories
    for source, label in image_labels.iteritems():
        upload_event_handler.add_image_dir(source_label=label, image_dir=image_snapshot_dirs[source])
    log.debug('Monitoring directories in {} for changes: {}'.format(
        snapshot_root, str(upload_event_handler.watched_dirs)))
    threads_tracked = Set()
    # file system listener
    observer = Observer()
    observer.name = observer.__class__.__name__
    observer.schedule(upload_event_handler, config.get('snapshots', 'root_dir'), recursive=True)
    if isinstance(sms_provider, GammuSMSProvider):
        for dir in sms_provider.spool_directories:
            observer.schedule(sms_provider, dir)
        # Since GammuSMSProvider is a Thread
        sms_provider.start()
        threads_tracked.add(sms_provider.getName())
    # start threads
    notifier.start()
    threads_tracked.add(notifier.getName())
    processor.start()
    threads_tracked.add(processor.getName())
    # start the collectors
    sample_event_handler.start()
    threads_tracked.add(sample_event_handler.getName())
    detector_event_handler.start()
    threads_tracked.add(detector_event_handler.getName())
    observer.start()
    threads_tracked.add(observer.getName())
    # start the Google Driver archiver last
    google_drive.start()
    threads_tracked.add(google_drive.getName())
    # start the REST interface
    #TODO: listen on eth0
    rest_api.run(host='0.0.0.0', port=80)
    try:
        time.sleep(1)
        notifier.play_file(os.path.join(TTS_DIR, config.get('app', 'tts_startup_sound')))
        while True:
            threads_alive = Set()
            for thread_info in threading.enumerate():
                if thread_info.isAlive():
                    threads_alive.add(thread_info.getName())
            if len(threads_tracked - threads_alive) > 0:
                message = 'A thread has died. Expected threads are [{}], missing is [{}].'.format(threads_tracked, threads_tracked - threads_alive)
                log.error(message)
                # bail out
                raise RuntimeError(message)
            # TODO: check on overdue heartbeats?
            time.sleep(60)
    except(KeyboardInterrupt, SystemExit):
        log.info('Stopping threads...')
        observer.stop()
        observer.join()
        log.info('Closing subscribers...')
        zmq_context.term()