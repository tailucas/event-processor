#!/usr/bin/python
import dateutil.parser
import hashlib
import logging
import logging.handlers

import os
import pytz
import sys
import time
import umsgpack
import urllib2

from ConfigParser import ConfigParser

import abc
from datetime import datetime, timedelta
from dateutil import tz
from mimetypes import MimeTypes
from mplayer import Player
from pprint import pprint
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from pydrive.files import FileNotUploadedError
from Queue import Queue, Empty
from threading import Thread
from time import sleep
from umsgpack import UnpackException
from urllib import pathname2url, urlencode
from watchdog.events import FileSystemEventHandler, FileModifiedEvent
from watchdog.observers import Observer

sys.displayhook = pprint

APP = os.path.basename(__file__)
DIR = os.path.abspath(os.path.dirname(__file__))
# set the working directory for libraries that assume this (such as PyDrive)
os.chdir(DIR)
log = logging.getLogger(APP)

TTS_URL = 'http://translate.google.com/translate_tts'

config = ConfigParser()
config.optionxform = str
config.read([os.path.expanduser('~/.{}'.format(APP))])

snapshot_root = config.get('snapshots', 'root_dir')
heartbeat_interval_seconds = int(config.get('snapshots', 'heartbeat_interval_seconds'))
notification_interval_seconds = int(config.get('snapshots', 'notification_interval_seconds'))
snapshot_validity_seconds = int(config.get('snapshots', 'snapshot_validity_seconds'))

snapshot_queue = Queue()
notification_queue = Queue()


class TTSProcessor(Thread):

    def __init__(self):
        super(TTSProcessor, self).__init__()
        self.player = None

    def run(self):
        # black-holding STDOUT causes properties to not work
        self.player = Player(stderr=open('/dev/null', 'w'), autospawn=True)
        while True:
            notification = None
            try:
                notification = notification_queue.get()
            except Exception as e:
                log.error(e)
            else:
                notification_queue.task_done()
            self.say(str(notification))

    def stop(self):
        if self.player:
            self.player.quit()

    def say(self, message):
        msg_checksum = TTSProcessor.checksum(message)
        log.debug("Checksum for \"{}\" is [{}]".format(message, msg_checksum))
        tts_file = "{}.mp3".format(msg_checksum)
        tts_path = os.path.join(DIR, tts_file)
        log.debug("{} exists? {}".format(tts_path, os.path.isfile(tts_path)))
        if not os.path.isfile(tts_path):
            values = {'tl': 'en', 'q': message}
            data = urlencode(values)
            request = urllib2.Request(TTS_URL, data)
            request.add_header('User-agent', 'Mozilla/5.0')
            opener = urllib2.build_opener()
            log.debug("Fetching \"{}\" from {}".format(message, TTS_URL))
            f = open(tts_path, "wb")
            f.write(opener.open(request).read())
            f.close()
            log.debug("Written {} bytes to {}".format(os.path.getsize(tts_path), tts_path))
        # now play
        self.player.loadfile(tts_path)
        delay = int(self.player.length)
        # block for the duration of this audio sample
        log.debug("Saying \"{}\" for {}s".format(message, delay))
        sleep(delay)

    @staticmethod
    def checksum(message):
        m = hashlib.md5()
        m.update(message)
        return m.hexdigest()


class Snapshot(object):
    __metaclass__ = abc.ABCMeta

    def __init__(self, source_label, file_path, validity_seconds):
        self.source_label = source_label
        self.file_path = file_path
        self.validity_seconds = validity_seconds

    @abc.abstractproperty
    def timestamp(self):
        return NotImplemented

    @abc.abstractproperty
    def is_expired(self):
        return NotImplemented

    @abc.abstractproperty
    def data(self):
        return NotImplemented

    @abc.abstractproperty
    def device_names(self):
        return NotImplemented

    @abc.abstractproperty
    def devices(self):
        return NotImplemented


class SampledSnapshot(Snapshot):

    def __init__(self, source_label, file_path, validity_seconds):
        super(SampledSnapshot, self).__init__(
            source_label=source_label,
            file_path=file_path,
            validity_seconds=validity_seconds)
        f = open(file_path)
        self.snapshot_data = umsgpack.unpack(f)
        self.timestamp_data = dateutil.parser.parse(self.snapshot_data['timestamp'])
        if self.timestamp_data.tzinfo is None:
            self.timestamp_data = self.timestamp_data.replace(tzinfo=tz.tzlocal())
        if 'data' in self.snapshot_data:
            self.devices_data = self.snapshot_data['data']
        else:
            self.devices_data = None

    @property
    def timestamp(self):
        return self.timestamp_data

    @property
    def is_expired(self):
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        return now - self.timestamp_data > timedelta(seconds=self.validity_seconds)

    @property
    def data(self):
        return self.snapshot_data

    @property
    def device_names(self):
        if self.devices_data is None:
            return None
        names = []
        for device_name in self.devices_data.keys():
            names.append(' '.join([self.source_label, device_name]))
        return names

    @property
    def devices(self):
        if self.devices_data is None:
            return {}
        return self.devices_data

    def __str__(self):
        string = "{} at {}".format(self.timestamp.strftime('%X %x %Z'), self.source_label)
        if self.devices:
            return string + ": {} devices: {}".format(
                len(self.devices), ','.join(self.devices.keys()))
        return string


class ImageSnapshot(Snapshot):

    def __init__(self, source_label, file_path, validity_seconds):
        super(ImageSnapshot, self).__init__(
            source_label=source_label,
            file_path=file_path,
            validity_seconds=validity_seconds)
        # default timestamp data to 'now'
        self.timestamp_data = datetime.utcnow().replace(tzinfo=pytz.utc)
        try:
            file_base_name = os.path.splitext(os.path.basename(file_path))[0]
            if '_' in file_base_name:
                date_string = file_base_name.split('_')[1]
            else:
                date_string = file_base_name
            self.timestamp_data = dateutil.parser.parse(date_string)
            if self.timestamp_data.tzinfo is None:
                self.timestamp_data = self.timestamp_data.replace(tzinfo=tz.tzlocal())
            log.debug("Parsed timestamp data from {}: {}".format(file_base_name, str(self.timestamp_data)))
        except ValueError:
            log.exception("Cannot parse date-like string {}. Defaulting to 'now'.".format(date_string))
        self.devices_data = {'camera': None}

    @property
    def timestamp(self):
        return self.timestamp_data

    @property
    def is_expired(self):
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        return now - self.timestamp_data > timedelta(seconds=self.validity_seconds)

    @property
    def data(self):
        return None

    @property
    def device_names(self):
        if self.devices_data is None:
            return None
        names = []
        for device_name in self.devices_data.keys():
            names.append(' '.join([self.source_label, device_name]))
        return names

    @property
    def devices(self):
        if self.devices_data is None:
            return {}
        return self.devices_data

    def __str__(self):
        string = "{} at {}".format(self.timestamp.strftime('%X %x %Z'), self.source_label)
        if self.devices:
            return string + ": {} devices: {}".format(
                len(self.devices), ','.join(self.devices.keys()))
        return string


class CloudStorage(object):
    __metaclass__ = abc.ABCMeta

    @abc.abstractmethod
    def upload(self, file_path, created_time):
        return NotImplemented


class GoogleDriveManager(Thread, CloudStorage):

    def __init__(self, gauth_creds_file, gdrive_folder):
        super(GoogleDriveManager, self).__init__()
        self._gdrive_folder = gdrive_folder
        if '~' in gauth_creds_file:
            self._gauth_creds_file = os.path.expanduser(gauth_creds_file)
        else:
            self._gauth_creds_file = os.path.abspath(gauth_creds_file)
        self._gauth = None
        self.drive = GoogleDrive(self.gauth)
        self._gdrive_folder_id = self._get_gdrive_folder_id(self.drive, gdrive_folder)
        self._folder_id_cache = {}
        self.mime = MimeTypes()
        # start the internal cleaning function
        self.daemon = True
        self.start()

    def archive(self, gdrive_file):
        filename = gdrive_file['title']
        now = datetime.utcnow().replace(tzinfo=pytz.utc)
        created_date = dateutil.parser.parse(gdrive_file['createdDate'])
        td = now - created_date
        if td > timedelta(days=1):
            log.info('Archiving {} created {} days ago.'.format(filename, td.days))
            ymd_date = created_date.strftime('%Y-%m-%d')
            if ymd_date in self._folder_id_cache:
                gdrive_folder_id = self._folder_id_cache[ymd_date]
            else:
                # create the required folder structure
                year_folder_name = created_date.strftime('%Y')
                year_folder_id = self._get_gdrive_folder_id(self.drive, year_folder_name, self._gdrive_folder_id)
                month_folder_name = created_date.strftime('%m')
                month_folder_id = self._get_gdrive_folder_id(self.drive, month_folder_name, year_folder_id)
                day_folder_name = created_date.strftime('%d')
                day_folder_id = self._get_gdrive_folder_id(self.drive, day_folder_name, month_folder_id)
                self._folder_id_cache[ymd_date] = day_folder_id
                gdrive_folder_id = day_folder_id
            log.debug('{} => folder key {} => folder ID {}'.format(filename, ymd_date, gdrive_folder_id))
            # reset the parent folders, include the existing parents if starred
            if gdrive_file['labels']['starred']:
                parents = []
                for parent in gdrive_file['parents']:
                    parent_id = parent['id']
                    parents.append(parent_id)
                    log.debug('Comparing parent {} with archive folder id {}'.format(parent_id, gdrive_folder_id))
                    if gdrive_folder_id == parent_id:
                        log.debug('{} already archived to {}'.format(filename, gdrive_folder_id))
                        return False
                log.info('Archiving starred file {}, but leaving existing parents intact.'.format(filename))
                # new parent for archival
                gdrive_parents = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
                # existing parents
                for parent in parents:
                    # simply appending the parents array returned by the service is insufficient
                    # possibly due to PyDrive's change detection, or Drive
                    gdrive_parents.append({"kind": "drive#parentReference", "id": parent})
                gdrive_file['parents'] = gdrive_parents
            else:
                # otherwise, clobber the existing parent information
                gdrive_file['parents'] = [{"kind": "drive#parentReference", "id": gdrive_folder_id}]
            # update the file metadata
            gdrive_file.Upload()
            return True
        return False

    def run(self):
        while True:
            log.debug("Listing files in {} ({})".format(self._gdrive_folder, self._gdrive_folder_id))
            file_list = self.drive.ListFile({
                'q': "'{}' in parents and trashed=false and mimeType != 'application/vnd.google-apps.folder'".format(
                    self._gdrive_folder_id
                ),
                'maxResults': 100,
            })
            archived = 0
            try:
                while True:
                    page = file_list.GetList()
                    for file1 in page:
                        if self.archive(gdrive_file=file1):
                            archived += 1
                    log.info('Archived {} image snapshots, continuing...'.format(str(archived)))
            except StopIteration:
                log.info('Archived {} image snapshots.'.format(str(archived)))
                pass
            # sleep until tomorrow
            sleep(60*60*24)

    @property
    def gauth(self):
        """
        :type self: UploadEventHandler
        """
        if self._gauth is None:
            self._gauth = GoogleAuth()
        if not os.path.exists(self._gauth_creds_file):
            log.debug("Google credentials not found in [{}]. Interactive setup may follow.".format(
                self._gauth_creds_file))
        # Try to load saved client credentials
        self._gauth.LoadCredentialsFile(self._gauth_creds_file)
        if self._gauth.credentials is None:
            # Authenticate if they're not there
            self._gauth.LocalWebserverAuth()
        elif self._gauth.access_token_expired:
            # Refresh them if expired
            self._gauth.Refresh()
        else:
            # Initialize the saved creds
            self._gauth.Authorize()
        if not os.path.exists(self._gauth_creds_file):
            # Save the current credentials to a file
            self._gauth.SaveCredentialsFile(self._gauth_creds_file)
            log.debug("Saved Google credentials to {}".format(self._gauth_creds_file))
        return self._gauth

    @staticmethod
    def _get_gdrive_folder_id(gdrive, gdrive_folder, parent_id='root', create=True):
        log.debug("Checking for existence of Google Drive folder '{}'".format(gdrive_folder))
        file_list = gdrive.ListFile({
            'q': "'{}' in parents and trashed=false and mimeType = 'application/vnd.google-apps.folder'"
            " and title = '{}'".format(parent_id, gdrive_folder)
        }).GetList()
        if len(file_list) == 0:
            if not create:
                return None
            log.debug("Creating Google Drive folder '{}' in parent folder '{}'".format(gdrive_folder, parent_id))
            folder = gdrive.CreateFile({
                'description': "Created by {}".format(APP), 'title': gdrive_folder,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [{"kind": "drive#parentReference", "id": parent_id}]
            })
            folder.Upload()
            folder_id = folder['id']
        elif len(file_list) == 1:
            folder_id = file_list[0]['id']
        else:
            raise RuntimeError("Unexpected result listing Google Drive for {}: {}".format(
                gdrive_folder, str(file_list)))
        log.debug("Google Drive folder ID for folder '{}' is '{}'".format(gdrive_folder, folder_id))
        return folder_id

    def upload(self, file_path, created_time=None):
        # upload the snapshot
        mime_type = self.mime.guess_type(pathname2url(file_path))
        if mime_type is not None:
            mime_type = mime_type[0]
        log.info("'{}' file {}".format(mime_type, file_path))
        try:
            created_date = None
            if created_time is None:
                log.debug("Uploading '{}' to Google Drive".format(file_path))
            else:
                # datetime.isoformat doesn't work because of the seconds
                # separator required by RFC3339, and the extra requirement to have
                # the colon in the TZ offset if not in UTC.
                offset = created_time.strftime('%z')
                created_date = created_time.strftime('%Y-%m-%dT%H:%M:%S.00') + offset[:3] + ':' + offset[3:]
                log.debug("Uploading '{}' to Google Drive with created time of {}".format(file_path, created_date))

            f = self.drive.CreateFile({
                'title': os.path.basename(file_path),
                'mimeType': mime_type,
                'createdDate': created_date,
                'parents': [{"kind": "drive#fileLink", "id": self._gdrive_folder_id}]
            })
            f.SetContentFile(file_path)
            f.Upload()
            log.info("Uploaded '{}' to Google Drive folder '{}' (ID: '{}')".format(
                os.path.basename(file_path), self._gdrive_folder, f['id']))
            pass
        except FileNotUploadedError:
            log.exception("Cannot upload {} to Google Drive".format(file_path))


class UploadEventHandler(FileSystemEventHandler):

    def __init__(self, cloud_storage=None):
        super(UploadEventHandler, self).__init__()
        self.last_modified = None
        self._cloud_storage = cloud_storage
        self.sample_dirs = {}
        self.image_dirs = {}

    def add_sample_dir(self, source_label, sample_dir):
        if source_label in self.sample_dirs:
            raise RuntimeError("Sample source label {} is already configured.".format(source_label))
        self.sample_dirs[source_label] = sample_dir

    def _sample_dir_label(self, event_directory):
        for dir_label, sample_dir in self.sample_dirs.iteritems():
            if sample_dir in event_directory:
                return dir_label
        return None

    def add_image_dir(self, source_label, image_dir):
        if source_label in self.image_dirs:
            raise RuntimeError("Image source label {} is already configured.".format(source_label))
        self.image_dirs[source_label] = image_dir

    def _image_dir_label(self, event_directory):
        for dir_label, image_dir in self.image_dirs.iteritems():
            if image_dir in event_directory:
                return dir_label
        return None

    @property
    def watched_dirs(self):
        return self.sample_dirs.items() + self.image_dirs.items()

    # we listen to on-modified events because the file is
    # created and then written to subsequently.
    def on_modified(self, event):
        """
        :type event: FileModifiedEvent
        """
        super(UploadEventHandler, self).on_modified(event)
        # the file has been written to and has valid content
        if not event.is_directory:
            snapshot_path = event.src_path
            # de-duplication
            if snapshot_path != self.last_modified:
                self.last_modified = snapshot_path
            else:
                return
            # cross-check that we're in the right place
            if snapshot_path.startswith(snapshot_root):
                # noinspection PyBroadException
                try:
                    # sampled snapshot?
                    source_label = self._sample_dir_label(snapshot_path)
                    if source_label:
                        try:
                            snapshot = SampledSnapshot(
                                source_label=source_label,
                                file_path=snapshot_path,
                                validity_seconds=snapshot_validity_seconds)
                            log_msg = "Snapshot: {} from {}".format(snapshot, snapshot_path)
                            if len(snapshot.devices) > 0:
                                log.info(log_msg)
                            else:
                                log.debug(log_msg)
                            snapshot_queue.put(snapshot)
                            pass
                        except UnpackException:
                            log.exception("Cannot unpack snapshot data in {}".format(snapshot_path))
                    # image snapshot?
                    source_label = self._image_dir_label(snapshot_path)
                    if source_label:
                        # create the snapshot data
                        snapshot = ImageSnapshot(
                            source_label=source_label,
                            file_path=snapshot_path,
                            validity_seconds=snapshot_validity_seconds)
                        log_msg = "Snapshot: {} from {}".format(snapshot, snapshot_path)
                        if len(snapshot.devices) > 0:
                            log.info(log_msg)
                        else:
                            log.debug(log_msg)
                        snapshot_queue.put(snapshot)
                        # upload the image snapshot
                        if self._cloud_storage:
                            self._cloud_storage.upload(
                                file_path=snapshot_path,
                                created_time=snapshot.timestamp)
                except Exception:
                    log.exception("Cannot process {}".format(snapshot_path))


class SnapshotProcessor(Thread):

    def __init__(self):
        super(SnapshotProcessor, self).__init__()
        self.last_snapshot = 0
        self.active_devices = {}
        self.latest_snapshot = datetime.utcnow().replace(tzinfo=pytz.utc)
        self.last_notification = 0

    def run(self):
        while True:
            snapshot = None
            try:
                snapshot = snapshot_queue.get(timeout=heartbeat_interval_seconds)
            except Empty:
                # deal with the heartbeat deficit below
                pass
            except Exception as e:
                log.error(e)
            else:
                snapshot_queue.task_done()

            if snapshot is not None:
                if snapshot.is_expired:
                    log.debug("Discarding expired snapshot {}".format(snapshot))
                    pass
                new_devices = False
                # only non-expired snapshots qualify as recent updates
                self.last_snapshot = time.time()
                if len(snapshot.devices) == 0:
                    self.active_devices.clear()
                else:
                    new_device_names = snapshot.device_names
                    # first purge dead keys
                    for device_name in self.active_devices.keys():
                        if device_name not in new_device_names:
                            del self.active_devices[device_name]
                    # now add new ones
                    for device_name in new_device_names:
                        if device_name not in self.active_devices:
                            new_devices = True
                            self.active_devices[device_name] = snapshot.timestamp
                if len(self.active_devices) > 0:
                    log.debug("{} active device(s).".format(len(self.active_devices)))
                last_notified = time.time() - self.last_notification
                if (last_notified > notification_interval_seconds or new_devices) \
                    and len(self.active_devices) > 0 \
                        and self.latest_snapshot < snapshot.timestamp:
                    self.latest_snapshot = snapshot.timestamp
                    self.last_notification = time.time()
                    log.info("Sending notification for {}".format(str(self.active_devices.keys())))
                    for device_name in self.active_devices.keys():
                        notification_queue.put(device_name)
            else:
                inactivity = time.time() - self.last_snapshot
                if inactivity > heartbeat_interval_seconds:
                    log.warn("A heartbeat or snapshot is overdue (after {} seconds)".format(heartbeat_interval_seconds))


if __name__ == "__main__":
    # set up logging
    log.setLevel(logging.DEBUG)
    syslog_handler = logging.handlers.SysLogHandler(address='/dev/log')
    formatter = logging.Formatter('%(name)s [%(levelname)s] %(message)s')
    syslog_handler.setFormatter(formatter)
    log.addHandler(syslog_handler)
    stream_handler = logging.StreamHandler(stream=sys.stdout)
    log.addHandler(stream_handler)
    # set up config
    sample_labels = dict(config.items('sample_sources'))
    image_labels = dict(config.items('images_sources'))
    sample_snapshot_dirs = dict(config.items('sample_snapshot_dirs'))
    image_snapshot_dirs = dict(config.items('image_snapshot_dirs'))
    # remap the labels to the directories
    if len(sample_labels) != len(sample_snapshot_dirs) or len(image_labels) != len(image_snapshot_dirs):
        raise RuntimeError("Invalid configuration. Sources and associated labels must match.")
    # ensure that auth is properly set up first
    google_drive = GoogleDriveManager(
        gauth_creds_file=config.get('gdrive', 'creds_file'),
        gdrive_folder=config.get('gdrive', 'folder'))
    upload_event_handler = UploadEventHandler(cloud_storage=google_drive)
    # monitor these directories
    for source, label in sample_labels.iteritems():
        upload_event_handler.add_sample_dir(source_label=label, sample_dir=sample_snapshot_dirs[source])
    for source, label in image_labels.iteritems():
        upload_event_handler.add_image_dir(source_label=label, image_dir=image_snapshot_dirs[source])
    log.debug("Monitoring directories in {} for changes: {}".format(
        snapshot_root, str(upload_event_handler.watched_dirs)))
    # start threads
    observer = Observer()
    observer.schedule(upload_event_handler, config.get('snapshots', 'root_dir'), recursive=True)
    observer.start()
    processor = SnapshotProcessor()
    processor.daemon = True
    processor.start()
    notifier = TTSProcessor()
    notifier.daemon = True
    notifier.start()
    try:
        while True:
            time.sleep(1)
    except(KeyboardInterrupt, SystemExit):
        log.info("Stopping threads...")
        observer.stop()
        log.info("Waiting for completion...")
        observer.join()
        log.info("Waiting for queue threads...")
        snapshot_queue.join()
        notification_queue.join()
        notifier.stop()
