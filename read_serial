#!/usr/bin/python
import json
import logging
import logging.handlers
import os
import pprint
import pytz
import serial
import sys
import time
import umsgpack

from ConfigParser import ConfigParser
from Queue import LifoQueue

from datetime import datetime
from ftplib import FTP
from tempfile import NamedTemporaryFile
from threading import Thread
from time import sleep

sys.displayhook = pprint.pprint

APP=os.path.basename(__file__)
log = logging.getLogger(APP)

EXPECTED_FIELDS=6
SAMPLE_DEVIATION_TOLERANCE=3
UPLOAD_TIMEOUT_SECONDS=1
HEARTBEAT_INTERVAL_SECONDS=5
SAMPLE_INTERVAL_SECONDS=1
SAMPLE_DEBOUNCE_COOLDOWN_SECONDS=1
DATE_FORMAT='%Y-%m-%dT%H:%M:%S.%f%z'

config = ConfigParser()
config.optionxform=str
config.read([os.path.expanduser('~/.{}'.format(APP))])

upload_queue = LifoQueue()

ftp_server=config.get('ftp', 'server')
ftp_user=config.get('ftp', 'user')
ftp_password=config.get('ftp', 'password')
ftp_dir = config.get('ftp', 'dir')

def upload(payload=None):
    now = datetime.utcnow()
    now = now.replace(tzinfo=pytz.utc)
    ts = now.strftime(DATE_FORMAT)
    output = {}
    output['timestamp'] = ts
    if payload is not None and len(payload) > 0:
	output['data'] = payload
    tempfile = NamedTemporaryFile(delete=False, dir='/tmp/')
    umsgpack.dump(output, tempfile)
    tempfile.close()
    filename = str(time.time())
    log.debug(json.dumps(output))
    while True:
        try:
            log.info('FTP {} bytes to ftp://{}@{}'.format(os.stat(tempfile.name).st_size, ftp_user, os.path.sep.join([ftp_server, ftp_dir, filename])))
            ftp = FTP(host=ftp_server, timeout=UPLOAD_TIMEOUT_SECONDS)
            ftp.login(user=ftp_user, passwd=ftp_password)
            ftp.cwd(ftp_dir)
            ftp.storbinary('STOR {}'.format(filename), open(tempfile.name))
            break
        except Exception as e:
            log.error(e)
        else:
            ftp.close()
    os.remove(tempfile.name)

def uploader():
    global last_upload
    last_upload = 0
    while True:
        sample = upload_queue.get()
        try:
            upload(sample)
        except Exception as e:
            log.error(e)
        else:
            upload_queue.task_done()
        last_upload = time.time()

def heartbeat():
    while True:
        sleep(HEARTBEAT_INTERVAL_SECONDS)
        inactivity = time.time() - last_upload
        if inactivity > HEARTBEAT_INTERVAL_SECONDS:
            upload()

if __name__ == "__main__":
    # set up logging
    log.setLevel(logging.DEBUG)
    syslog_handler = logging.handlers.SysLogHandler(address = '/dev/log')
    formatter = logging.Formatter('%(name)s [%(levelname)s] %(message)s')
    syslog_handler.setFormatter(formatter)
    log.addHandler(syslog_handler)
    stream_handler = logging.StreamHandler(stream=sys.stdout)
    log.addHandler(stream_handler)
    # start up threads
    uploader = Thread(target=uploader)
    uploader.daemon = True
    uploader.start()
    heartbeat = Thread(target=heartbeat)
    heartbeat.daemon = True
    heartbeat.start()
    com1 = serial.Serial(port=config.get('serial', 'port'), baudrate=config.getint('serial', 'baudrate'))
    field_labels = dict(config.items('field_labels'))
    field_normal_values = dict(config.items('field_normal_values'))
    field_range_labels = dict(config.items('field_range_labels'))
    # split the range labels for easy processing
    expanded_field_range_labels = {}
    for field in field_range_labels:
        pairs = map(lambda s: s.split(':'), field_range_labels[field].split(','))
        expanded_field_range_labels[field] = dict({k:int(v) for k,v in pairs})
    field_range_labels = expanded_field_range_labels
    try:
        # we map samples to values
        sample_value_history = {}
        for label in field_labels:
            # we map sample values to the last time that value was seen
            sample_label = field_labels[label]
            sample_value_history[sample_label] = {}
        while True:
            data = com1.readline()
            sample_time = time.time()
            if data is None:
                continue
            fields = data.rstrip().split(',')
            if len(fields) != EXPECTED_FIELDS:
                continue
            try:
                # extract the pairs from each line read
                pairs = map(lambda s: s.split(':'), fields)
                # convert tuples to dict
                samples = dict({k:int(v) for k,v in pairs})
            except (IndexError, ValueError):
                continue
            output_samples = {}
            # if there are no label mappings, upload as is
            if field_labels is None or len(field_labels) == 0:
                output_samples = samples
            # otherwise, upload only samples with labels
            for label in field_labels:
                try:
                    # serial interface can truncate labels too
                    sample_value = samples[label]
                except KeyError:
                    continue
                sample_label = field_labels[label]
                # filter out values in the normal range
                if label in field_normal_values:
                    normal_value = int(field_normal_values[label])
                    if abs(sample_value - normal_value) <= SAMPLE_DEVIATION_TOLERANCE:
                        continue
                # when last did we see this value?
                value_last_seen = 0
                if sample_value in sample_value_history[sample_label]:
                    value_last_seen = sample_value_history[sample_label][sample_value]
                # update the last time seen for this value
                sample_value_history[sample_label][sample_value] = sample_time
                # output the value only if it was seen more than the debounce tolerance ago
                if time.time() - value_last_seen < SAMPLE_DEBOUNCE_COOLDOWN_SECONDS:
                    log.debug("Debouncing {} value of {} seen within {} seconds ago.".format(sample_label, sample_value, SAMPLE_DEBOUNCE_COOLDOWN_SECONDS))
                    continue
                # now annotate the label with the range label
                if label in field_range_labels:
                    for range_label,range_value in field_range_labels[label].iteritems():
                        if abs(sample_value - range_value) <= SAMPLE_DEVIATION_TOLERANCE:
                            sample_label = ' '.join([sample_label, range_label])
                # add the sample to the output
                output_samples[sample_label] = sample_value
	    if len(output_samples) > 0:
                log.debug("{} samples enqueued behind {} others for upload.".format(len(output_samples), upload_queue.qsize()))
                upload_queue.put(output_samples)
                # do not overwhelm the uploader, but keep sample rate as high as the input provides it
                sleep(SAMPLE_INTERVAL_SECONDS)
                # throw away the intermediate data if the external sample rate exceeded our own
                com1.flushInput()
    except(KeyboardInterrupt, SystemExit):
        log.info("Closing serial connection...")
        com1.close()
        log.info("Waiting for queue threads...")
        upload_queue.join()
