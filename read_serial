#!/usr/bin/python
import json
import logging
import logging.handlers
import os
import pprint
import pytz
import serial
import sys
import time
import umsgpack

from ConfigParser import ConfigParser
from Queue import Queue

from datetime import datetime
from ftplib import FTP
from tempfile import NamedTemporaryFile
from threading import Thread
from time import sleep

sys.displayhook = pprint.pprint

APP=os.path.basename(__file__)
log = logging.getLogger(APP)

EXPECTED_FIELDS=6
SAMPLE_DEVIATION_TOLERANCE=3
UPLOAD_TIMEOUT_SECONDS=1
HEARTBEAT_INTERVAL_SECONDS=60
SAMPLE_INTERVAL_SECONDS=1
DATE_FORMAT='%Y-%m-%dT%H:%M:%S.%f%z'

config = ConfigParser()
config.optionxform=str
config.read([os.path.expanduser('~/.{}'.format(APP))])

upload_queue = Queue()

ftp_server=config.get('ftp', 'server')
ftp_user=config.get('ftp', 'user')
ftp_password=config.get('ftp', 'password')
ftp_dir = config.get('ftp', 'dir')

def upload(payload=None):
    now = datetime.utcnow()
    now = now.replace(tzinfo=pytz.utc)
    ts = now.strftime(DATE_FORMAT)
    output = {}
    output['timestamp'] = ts
    if payload is not None and len(payload) > 0:
	output['data'] = payload
    tempfile = NamedTemporaryFile(delete=False, dir='/tmp/')
    umsgpack.dump(output, tempfile)
    tempfile.close()
    filename = str(time.time())
    log.debug(json.dumps(output))
    while True:
        try:
            log.info('FTP {} bytes to ftp://{}@{}'.format(os.stat(tempfile.name).st_size, ftp_user, os.path.sep.join([ftp_server, ftp_dir, filename])))
            ftp = FTP(host=ftp_server, timeout=UPLOAD_TIMEOUT_SECONDS)
            ftp.login(user=ftp_user, passwd=ftp_password)
            ftp.cwd(ftp_dir)
            ftp.storbinary('STOR {}'.format(filename), open(tempfile.name))
            break
        except Exception as e:
            log.error(e)
        else:
            ftp.close()
    os.remove(tempfile.name)

def uploader():
    global last_upload
    last_upload = 0
    while True:
        sample = upload_queue.get()
        try:
            upload(sample)
        except Exception as e:
            log.error(e)
        else:
            upload_queue.task_done()
        last_upload = time.time()

def heartbeat():
    while True:
        sleep(HEARTBEAT_INTERVAL_SECONDS)
        inactivity = time.time() - last_upload
        if inactivity > HEARTBEAT_INTERVAL_SECONDS:
            upload()

if __name__ == "__main__":
    # set up logging
    log.setLevel(logging.DEBUG)
    syslog_handler = logging.handlers.SysLogHandler(address = '/dev/log')
    formatter = logging.Formatter('%(name)s [%(levelname)s] %(message)s')
    syslog_handler.setFormatter(formatter)
    log.addHandler(syslog_handler)
    stream_handler = logging.StreamHandler(stream=sys.stdout)
    log.addHandler(stream_handler)
    # start up threads
    uploader = Thread(target=uploader)
    uploader.daemon = True
    uploader.start()
    heartbeat = Thread(target=heartbeat)
    heartbeat.daemon = True
    heartbeat.start()
    com1 = serial.Serial(port=config.get('serial', 'port'), baudrate=config.getint('serial', 'baudrate'))
    field_labels = dict(config.items('field_labels'))
    field_normal_values = dict(config.items('field_normal_values'))
    try:
        while True:
            data = com1.readline()
            if data is None:
                continue
            fields = data.rstrip().split(',')
            if len(fields) != EXPECTED_FIELDS:
                continue
            try:
                # extract the pairs from each line read
                pairs = map(lambda s: s.split(':'), fields)
                # convert tuples to dict
                samples = dict({k:int(v) for k,v in pairs})
            except (IndexError, ValueError):
                continue
            output_samples = {}
            # if there are no label mappings, upload as is
            if field_labels is None or len(field_labels) == 0:
                output_samples = samples
            # otherwise, upload only samples with labels
            for label in field_labels:
                try:
                    # serial interface can truncate labels too
                    sample_value = samples[label]
                except KeyError:
                    continue
                sample_label = field_labels[label]
                # filter out values in the normal range
                if label in field_normal_values:
                    normal_value = int(field_normal_values[label])
                    if abs(sample_value - normal_value) <= SAMPLE_DEVIATION_TOLERANCE:
                        continue
                output_samples[sample_label] = sample_value
	    if len(output_samples) > 0:
                log.debug("{} samples enqueued behind {} others for upload.".format(len(output_samples), upload_queue.qsize()))
                upload_queue.put(output_samples)
                # do not overwhelm the uploader, but keep sample rate as high as the input provides it
                sleep(SAMPLE_INTERVAL_SECONDS)
    except(KeyboardInterrupt, SystemExit):
        log.info("Closing serial connection...")
        com1.close()
        log.info("Waiting for queue threads...")
        upload_queue.join()
