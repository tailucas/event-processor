#!/usr/bin/python
import json
import logging
import logging.handlers
import os
import pprint
import pytz
import serial
import signal
import subprocess
import sys
import time
import zmq

from ConfigParser import ConfigParser

from datetime import datetime
from serial.serialutil import SerialException
from threading import Thread
from time import sleep

sys.displayhook = pprint.pprint

APP = os.path.basename(__file__)
log = logging.getLogger(APP)

EXPECTED_FIELDS = 6
SAMPLE_DEVIATION_TOLERANCE = 4
UPLOAD_TIMEOUT_SECONDS = 1
HEARTBEAT_INTERVAL_SECONDS = 5
SAMPLE_INTERVAL_SECONDS = 1
SAMPLE_DEBOUNCE_COOLDOWN_SECONDS = 60
DEVICE_MONITOR_CONCURRENCY = 4
DATE_FORMAT = '%Y-%m-%dT%H:%M:%S.%f%z'
URL_WORKER_SAMPLES = 'inproc://samples'
URL_WORKER_PROBE_RESULT = 'inproc://probe-result'
URL_WORKER_PROBE_START = 'inproc://probe-start'


config = ConfigParser()
config.optionxform = str
config.read([os.path.expanduser('~/.{}'.format(APP))])

location = config.get('app', 'location')
zmq_context = zmq.Context()

def exec_cmd(cmd):
    p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
    out, err = p.communicate()
    return out, err, p.returncode


def uploader():
    # Socket to talk to the outside world
    publisher = zmq_context.socket(zmq.PUB)
    publisher.bind('tcp://*:{port}'.format(port=config.get('zmq', 'port')))
    # Socket to talk to dispatcher
    samples = zmq_context.socket(zmq.PULL)
    samples.connect(URL_WORKER_SAMPLES)
    probes = zmq_context.socket(zmq.PULL)
    probes.connect(URL_WORKER_PROBE_RESULT)
    # poller
    poller = zmq.Poller()
    poller.register(samples, zmq.POLLIN)
    poller.register(probes, zmq.POLLIN)
    while True:
        socks = dict(poller.poll())
        for socket in socks:
            log.debug('{} events for {} peers'.format(publisher.events, publisher.peers))
            publisher.send_pyobj(socket.recv())


def make_payload(timestamp=None, data=None):
    payload = dict()
    if timestamp is None:
        timestamp = time.now()
    payload['timestamp'] = datetime.utcfromtimestamp(timestamp).replace(tzinfo=pytz.utc).strftime(DATE_FORMAT)
    payload['location'] = location
    if data is not None and len(data) > 0:
        payload['data'] = data
    log.debug(json.dumps(payload))
    return payload


class BluetoothDeviceMonitor(Thread):

    def __init__(self):
        super(BluetoothDeviceMonitor, self).__init__()
        self.daemon = True

        devices = config.get('bluetooth', 'devices').replace('-', ':').upper().split(',')
        owners = config.get('bluetooth', 'owners').split(',')
        self.owner_devices = dict(zip(owners, devices))

    @staticmethod
    def l2ping(owner, device):
        log.debug('l2ping {} @ {}...'.format(owner, device))
        out, err, rc = exec_cmd(['sudo', '/usr/bin/l2ping', '-t1', '-c1', device])
        if rc == 0:
            log.debug('l2ping output: {}'.format(out))
            return out
        else:
            log.error('Non-zero exit {} for l2ping output: {} {}'.format(rc, out, err))
        return None

    def run(self):
        # first test for a Bluetooth adaptor and format this type of output
        # Devices:
        # hci0    00:09:DD:50:17:18
        out, err, rc = exec_cmd(['hcitool', 'dev'])
        if rc != 0:
            raise RuntimeError('Cannot query hcitool to find Bluetooth adaptors: {} {}'.format(out, err))
        hcitool = out.rstrip().split('\n')
        if len(hcitool) < 2:
            raise RuntimeError('No Bluetooth adaptors found using hcitool.')
        for line in hcitool[1:]:
            log.info('Bluetooth adaptor found: {}'.format(' '.join(line.split())))
        # Socket to initiate probe
        probe_start = zmq_context.socket(zmq.PULL)
        probe_start.connect(URL_WORKER_PROBE_START)
        # Socket to talk to publisher
        publisher = zmq_context.socket(zmq.PUSH)
        publisher.bind(URL_WORKER_PROBE_RESULT)
        while True:
            probe_start.recv()
            for owner, device in self.owner_devices.items():
                if self.l2ping(owner, device) is not None:
                    publisher.send_pyobj(make_payload(timestamp=None, data={'devices_nearby': {owner: device}}))

probe_start = None


def signal_handler(signum, frame):
    log.warn('Signal {} received.'.format(signum))
    probe_start.send_string('probe')


if __name__ == "__main__":
    # set up logging
    log.setLevel(logging.DEBUG)
    syslog_handler = logging.handlers.SysLogHandler(address='/dev/log')
    formatter = logging.Formatter('%(name)s [%(levelname)s] %(message)s')
    syslog_handler.setFormatter(formatter)
    log.addHandler(syslog_handler)
    stream_handler = logging.StreamHandler(stream=sys.stdout)
    log.addHandler(stream_handler)
    # Socket to talk to workers
    sample_sink = zmq_context.socket(zmq.PUSH)
    sample_sink.bind(URL_WORKER_SAMPLES)
    probe_start = zmq_context.socket(zmq.PUSH)
    probe_start.bind(URL_WORKER_PROBE_START)
    # start up threads
    uploader = Thread(target=uploader)
    uploader.start()
    bluetooth_monitor = BluetoothDeviceMonitor()
    bluetooth_monitor.start()
    # set up signal handlers
    signal.signal(signal.SIGHUP, signal_handler)
    # start sampler
    com1 = serial.Serial(port=config.get('serial', 'port'), baudrate=config.getint('serial', 'baudrate'))
    field_labels = dict(config.items('field_labels'))
    field_normal_values = dict(config.items('field_normal_values'))
    field_active_labels = dict(config.items('field_active_labels'))
    field_active_values = dict(config.items('field_active_values'))
    # split the range labels for easy processing
    expanded_field_active_labels = dict()
    for field in field_active_labels:
        pairs = map(lambda s: s.split(':'), field_active_labels[field].split(','))
        expanded_field_active_labels[field] = dict({k: int(v) for k, v in pairs})
    field_active_labels = expanded_field_active_labels
    # split out the active values
    expanded_field_active_values = dict()
    for field in field_active_values:
        expanded_field_active_values[field] = list({int(v) for v in field_active_values[field].split(',')})
    field_active_values = expanded_field_active_values
    try:
        # we map samples to values
        sample_value_history = dict()
        for label in field_labels:
            # we map sample values to the last time that value was seen
            sample_label = field_labels[label]
            sample_value_history[sample_label] = dict()
        # when last did we upload
        last_upload = 0
        while True:
            try:
                data = com1.readline()
            except SerialException:
                if com1.closed:
                    break
                # if the process is signalled
                continue
            sample_time = time.time()
            if data is None:
                continue
            fields = data.rstrip().split(',')
            if len(fields) != EXPECTED_FIELDS:
                continue
            try:
                # extract the pairs from each line read
                pairs = map(lambda s: s.split(':'), fields)
                # convert tuples to dict
                samples = dict({k: int(v) for k, v in pairs})
            except (IndexError, ValueError):
                continue
            output_samples = dict()
            # if there are no label mappings, upload as is
            if field_labels is None or len(field_labels) == 0:
                output_samples = samples
            # otherwise, upload only samples with labels
            for label in field_labels:
                try:
                    # serial interface can truncate labels too
                    sample_value = samples[label]
                except KeyError:
                    continue
                sample_label = field_labels[label]
                # filter out values in the normal range
                if label in field_normal_values:
                    normal_value = int(field_normal_values[label])
                    if abs(sample_value - normal_value) <= SAMPLE_DEVIATION_TOLERANCE:
                        continue
                # clamp the value based on the debounce settings
                if label in field_active_values:
                    for debounce_value in field_active_values[label]:
                        if abs(sample_value - debounce_value) <= SAMPLE_DEVIATION_TOLERANCE:
                            sample_value = debounce_value
                # when last did we see this value?
                value_last_seen = 0
                if sample_value in sample_value_history[sample_label]:
                    value_last_seen = sample_value_history[sample_label][sample_value]
                # output the value only if it was seen more than the debounce tolerance ago
                time_delta = time.time() - value_last_seen
                if time_delta < SAMPLE_DEBOUNCE_COOLDOWN_SECONDS:
                    log.debug('Debouncing {} value of {} for another {} seconds.'.format(
                        sample_label, sample_value, int(SAMPLE_DEBOUNCE_COOLDOWN_SECONDS-time_delta)))
                    continue
                else:
                    # update the last time seen for this value
                    sample_value_history[sample_label][sample_value] = sample_time
                # now annotate the label with the range label
                if label in field_active_labels:
                    for range_label, range_value in field_active_labels[label].iteritems():
                        if abs(sample_value - range_value) <= SAMPLE_DEVIATION_TOLERANCE:
                            sample_label = ' '.join([sample_label, range_label])
                # add the sample to the output
                output_samples[sample_label] = sample_value
            # heartbeat?
            if len(output_samples) == 0:
                inactivity = time.time() - last_upload
                if inactivity > HEARTBEAT_INTERVAL_SECONDS:
                    sample_sink.send_pyobj(make_payload())
                    last_upload = time.time()
            else:
                # there's something going on here
                probe_start.send_string('main')
                sample_sink.send_pyobj(make_payload(timestamp=sample_time, data={'samples': output_samples}))
                # do not overwhelm the uploader, but keep sample rate as high as the input provides it
                sleep(SAMPLE_INTERVAL_SECONDS)
                # throw away the intermediate data if the external sample rate exceeds our ability to consume it
                com1.flushInput()
    except(KeyboardInterrupt, SystemExit):
        log.info('Closing serial connection...')
        com1.close()
        log.info('Stopping workers...')
        sample_sink.close()
        probe_start.close()
        uploader.close()
        log.info('Terminating messaging context...')
        zmq_context.term()