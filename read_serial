#!/usr/bin/python
import json
import logging
import logging.handlers
import os
import pprint
import pytz
import serial
import subprocess
import sys
import time
import umsgpack

import StringIO

from ConfigParser import ConfigParser
from Queue import LifoQueue

from datetime import datetime
from ftplib import FTP
from threading import Thread, Condition
from time import sleep

sys.displayhook = pprint.pprint

APP = os.path.basename(__file__)
log = logging.getLogger(APP)

EXPECTED_FIELDS = 6
SAMPLE_DEVIATION_TOLERANCE = 4
UPLOAD_TIMEOUT_SECONDS = 1
HEARTBEAT_INTERVAL_SECONDS = 5
SAMPLE_INTERVAL_SECONDS = 1
SAMPLE_DEBOUNCE_COOLDOWN_SECONDS = 60
DATE_FORMAT = '%Y-%m-%dT%H:%M:%S.%f%z'

config = ConfigParser()
config.optionxform = str
config.read([os.path.expanduser('~/.{}'.format(APP))])

upload_queue = LifoQueue()

ftp_server = config.get('ftp', 'server')
ftp_user = config.get('ftp', 'user')
ftp_password = config.get('ftp', 'password')
ftp_dir = config.get('ftp', 'dir')

trigger_condition = Condition()


def upload(payload=None):
    now = datetime.utcnow()
    now = now.replace(tzinfo=pytz.utc)
    ts = now.strftime(DATE_FORMAT)
    output = dict()
    output['timestamp'] = ts
    if payload is not None and len(payload) > 0:
        output['data'] = payload
    log.debug(json.dumps(output))
    fh = StringIO(umsgpack.dumps(output))
    filename = str(time.time())
    while True:
        try:
            log.info('ftp://{}@{}'.format(
                ftp_user,
                os.path.sep.join([ftp_server, ftp_dir, filename])))
            ftp = FTP(host=ftp_server, timeout=UPLOAD_TIMEOUT_SECONDS)
            ftp.login(user=ftp_user, passwd=ftp_password)
            ftp.cwd(ftp_dir)
            ftp.storbinary('STOR {}'.format(filename), fh)
            ftp.close()
            break
        except Exception as e:
            log.error(e)
    fh.close()


def uploader():
    global last_upload
    last_upload = 0
    while True:
        sample = upload_queue.get()
        try:
            upload(sample)
        except Exception as e:
            log.error(e)
        else:
            upload_queue.task_done()
        last_upload = time.time()


class BluetoothDeviceMonitor(Thread):

    def __init__(self):
        super(BluetoothDeviceMonitor, self).__init__()
        self.daemon = True

        devices = config.get('bluetooth', 'devices').replace('-', ':').upper().split(',')
        owners = config.get('bluetooth', 'owners').split(',')
        self.owner_devices = dict(zip(owners, devices))

    @staticmethod
    def exec_cmd(cmd):
        p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
        out, err = p.communicate()
        return out, p.returncode

    def run(self):
        log.debug("Bluetooth poller thread awakened.")
        while True:
            trigger_condition.wait()
            for owner, device in self.owner_devices:
                output, rc = self.exec_cmd(['sudo', '/usr/bin/l2ping', '-t1', '-c1', device])
                log.debug('l2ping for {}: {}'.format(owner, output))
                if rc == 0:
                    upload_queue.put({'{} is here.'.format(owner): rc})


def heartbeat():
    while True:
        sleep(HEARTBEAT_INTERVAL_SECONDS)
        inactivity = time.time() - last_upload
        if inactivity > HEARTBEAT_INTERVAL_SECONDS:
            upload()

if __name__ == "__main__":
    # set up logging
    log.setLevel(logging.DEBUG)
    syslog_handler = logging.handlers.SysLogHandler(address='/dev/log')
    formatter = logging.Formatter('%(name)s [%(levelname)s] %(message)s')
    syslog_handler.setFormatter(formatter)
    log.addHandler(syslog_handler)
    stream_handler = logging.StreamHandler(stream=sys.stdout)
    log.addHandler(stream_handler)
    # start up threads
    uploader = Thread(target=uploader)
    uploader.daemon = True
    uploader.start()
    heartbeat = Thread(target=heartbeat)
    heartbeat.daemon = True
    heartbeat.start()
    bluetooth_monitor = BluetoothDeviceMonitor()
    bluetooth_monitor.start()
    com1 = serial.Serial(port=config.get('serial', 'port'), baudrate=config.getint('serial', 'baudrate'))
    field_labels = dict(config.items('field_labels'))
    field_normal_values = dict(config.items('field_normal_values'))
    field_range_labels = dict(config.items('field_range_labels'))
    field_debounce_values = dict(config.items('field_debounce_values'))
    # split the range labels for easy processing
    expanded_field_range_labels = dict()
    for field in field_range_labels:
        pairs = map(lambda s: s.split(':'), field_range_labels[field].split(','))
        expanded_field_range_labels[field] = dict({k: int(v) for k, v in pairs})
    field_range_labels = expanded_field_range_labels
    # split out the debounce values
    expanded_field_debounce_values = dict()
    for field in field_debounce_values:
        expanded_field_debounce_values[field] = list({int(v) for v in field_debounce_values[field].split(',')})
    field_debounce_values = expanded_field_debounce_values
    try:
        # we map samples to values
        sample_value_history = dict()
        for label in field_labels:
            # we map sample values to the last time that value was seen
            sample_label = field_labels[label]
            sample_value_history[sample_label] = dict()
        while True:
            data = com1.readline()
            sample_time = time.time()
            if data is None:
                continue
            fields = data.rstrip().split(',')
            if len(fields) != EXPECTED_FIELDS:
                continue
            try:
                # extract the pairs from each line read
                pairs = map(lambda s: s.split(':'), fields)
                # convert tuples to dict
                samples = dict({k: int(v) for k, v in pairs})
            except (IndexError, ValueError):
                continue
            output_samples = dict()
            # if there are no label mappings, upload as is
            if field_labels is None or len(field_labels) == 0:
                output_samples = samples
            # otherwise, upload only samples with labels
            for label in field_labels:
                try:
                    # serial interface can truncate labels too
                    sample_value = samples[label]
                except KeyError:
                    continue
                sample_label = field_labels[label]
                # filter out values in the normal range
                if label in field_normal_values:
                    normal_value = int(field_normal_values[label])
                    if abs(sample_value - normal_value) <= SAMPLE_DEVIATION_TOLERANCE:
                        continue
                # clamp the value based on the debounce settings
                if label in field_debounce_values:
                    for debounce_value in field_debounce_values[label]:
                        if abs(sample_value - debounce_value) <= SAMPLE_DEVIATION_TOLERANCE:
                            sample_value = debounce_value
                # when last did we see this value?
                value_last_seen = 0
                if sample_value in sample_value_history[sample_label]:
                    value_last_seen = sample_value_history[sample_label][sample_value]
                # output the value only if it was seen more than the debounce tolerance ago
                time_delta = time.time() - value_last_seen
                if time_delta < SAMPLE_DEBOUNCE_COOLDOWN_SECONDS:
                    log.debug("Debouncing {} value of {} for another {} seconds.".format(
                        sample_label, sample_value, int(SAMPLE_DEBOUNCE_COOLDOWN_SECONDS-time_delta)))
                    continue
                else:
                    # update the last time seen for this value
                    sample_value_history[sample_label][sample_value] = sample_time
                # now annotate the label with the range label
                if label in field_range_labels:
                    for range_label, range_value in field_range_labels[label].iteritems():
                        if abs(sample_value - range_value) <= SAMPLE_DEVIATION_TOLERANCE:
                            sample_label = ' '.join([sample_label, range_label])
                # add the sample to the output
                output_samples[sample_label] = sample_value
            if len(output_samples) > 0:
                trigger_condition.notify()
                log.debug("{} samples enqueued behind {} others for upload.".format(
                    len(output_samples),
                    upload_queue.qsize()))
                upload_queue.put(output_samples)
                # do not overwhelm the uploader, but keep sample rate as high as the input provides it
                sleep(SAMPLE_INTERVAL_SECONDS)
                # throw away the intermediate data if the external sample rate exceeds our ability to consume it
                com1.flushInput()
    except(KeyboardInterrupt, SystemExit):
        log.info("Closing serial connection...")
        com1.close()
        log.info("Waiting for queue threads...")
        upload_queue.join()
