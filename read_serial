#!/usr/bin/python
import json
import os
import pytz
import serial
import time
import umsgpack

from ConfigParser import ConfigParser
from Queue import Queue

from datetime import datetime
from ftplib import FTP
from syslog import LOG_PID, syslog, openlog
from threading import Thread
from time import sleep

openlog(logoption=LOG_PID)

APP=os.path.basename(__file__)
EXPECTED_FIELDS=6
SAMPLE_THRESHOLD=50

config = ConfigParser()
config.read([os.path.expanduser('~/.{}'.format(APP))])

upload_queue = Queue()

def log(msg):
    print msg
    syslog(msg)

def field_labels():
    if config.has_section('field_labels'):
        return map(lambda s: s[1], config.items('field_labels'))
    return None

def xlate_field_name(name):
    if config.has_section('field_labels'):
        if config.has_option('field_labels', name):
            return config.get('field_labels', name)
    return name

def upload(payload=None):
    now = datetime.utcnow()
    now = now.replace(tzinfo=pytz.utc)
    ts = now.strftime("%Y-%m-%dT%H:%M:%S%z")
    output = {}
    output['timestamp'] = ts
    if payload is not None and len(payload) > 0:
	output['data'] = payload
    log(json.dumps(output))
    bdata = umsgpack.dumps(output)

def uploader():
    while True:
        sample = upload_queue.get()
        upload(sample)
        upload_queue.task_done()

uploader = Thread(target=uploader)
uploader.daemon = True
uploader.start()
com1 = serial.Serial(port=config.get('serial', 'port'), baudrate=config.getint('serial', 'baudrate'))
while True:
    try:
        data = com1.readline()
        if data is None:
            continue
        fields = data.rstrip().split(',')
        if len(fields) != EXPECTED_FIELDS:
            continue
        try:
            # extract the pairs from each line read
            pairs = map(lambda s: s.split(':'), fields)
            # convert tuples to dict
            samples = dict(pairs)
            # translate field names and cast keys to int
            samples = {xlate_field_name(k):int(v) for k,v in samples.items()}
        except (IndexError, ValueError):
            continue
        # strip out undefined fields or fields under threshold
        labels = field_labels()
        if labels is not None:
            reduced_samples = {}
            for label in labels:
		if samples[label] >= SAMPLE_THRESHOLD:
                    reduced_samples[label] = samples[label]
            samples = reduced_samples
	if len(samples) > 0:
            upload_queue.put(samples)
    except(KeyboardInterrupt, SystemExit):
        log("Closing serial connection...")
        com1.close()
        log("Waiting for queue threads...")
        upload_queue.join()
        break
