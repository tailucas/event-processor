#!/usr/bin/python
import dateutil.parser
import hashlib
import logging
import logging.handlers

import abc
import os
import pytz
import signal
import sys
import threading
import time
import umsgpack
import zmq

from ConfigParser import ConfigParser

from datetime import datetime, timedelta
from dateutil import tz
from pprint import pprint
from sets import Set
from Queue import Queue, Empty
from threading import Thread, Timer
from time import sleep
from umsgpack import UnpackException
from zmq import ContextTerminated
from flask import Flask, request, render_template, url_for, redirect

# unbuffered STDOUT for print
sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)
sys.displayhook = pprint

APP = os.path.basename(__file__)
DIR = os.path.abspath(os.path.dirname(__file__))
# set the working directory for libraries that assume this (such as PyDrive)
os.chdir(DIR)
log = logging.getLogger(APP)
# do not propagate to console logging
log.propagate = False

config = ConfigParser()
config.optionxform = str
config.read([os.path.join(DIR, '{}.conf'.format(APP))])

rest_api = Flask(APP)

URL_WORKER_EVENT_PROCESSOR = 'inproc://event-processor'
zmq_context = zmq.Context()


def signal_handler(signum, frame):
    log.warn('Signal {} received.'.format(signum))
    log.setLevel(logging.DEBUG)


@rest_api.route('/logging')
def debug():
    log.setLevel(request.args.get('level'))
    return 'OK'


@rest_api.route('/relay_ctrl_toggle', methods=['GET','POST'])
def relay_ctrl_toggle():
    #if SnapshotProcessor._relay_ctrl:
    #    SnapshotProcessor._relay_ctrl = False
    #else:
    #    SnapshotProcessor._relay_ctrl = True
    return redirect(url_for('index'))

@rest_api.route('/notification_toggle', methods=['GET','POST'])
def notification_toggle():
    #if SnapshotProcessor._notification_ctrl:
    #    SnapshotProcessor._notification_ctrl = False
    #else:
    #    SnapshotProcessor._notification_ctrl = True
    return redirect(url_for('index'))


@rest_api.route('/', methods=['GET','POST'])
def index():
    relays = 'Beep Beeps {}'
    #if SnapshotProcessor._relay_ctrl:
    #    relays = relays.format('ON')
    #else:
    #    relays = relays.format('OFF')
    notifications = 'Crazy Lady {}'
    #if SnapshotProcessor._notification_ctrl:
    #    notifications = notifications.format('ON')
    #else:
    #    notifications = notifications.format('OFF')
    return render_template('index.html', relays=relays, notifications=notifications)


def run_flask():
    rest_api.run(host=config.get('app', 'eth0_ip'), port=5000)


class ZMQEndpoint(object):
    __metaclass__ = abc.ABCMeta

    def __init__(self, zmq_sockets):
        self._zmq_sockets = zmq_sockets

    def close(self):
        for socket in self._zmq_sockets:
            socket.close()


class EventProcessor(Thread, ZMQEndpoint):

    def __init__(self):
        super(EventProcessor, self).__init__()
        self.name = self.__class__.__name__
        self.daemon = True

        self.socket = zmq_context.socket(zmq.PULL)
        self.socket.bind(URL_WORKER_EVENT_PROCESSOR)
        ZMQEndpoint.__init__(self, zmq_sockets=[self.socket])

    def run(self):
        while True:
            try:
                event = self.socket.recv_pyobj()
                log.debug(event)
            except ContextTerminated:
                break
            except Exception:
                log.exception(self.__class__.__name__)
                continue


class SourceSubscriber(Thread, ZMQEndpoint):

    def __init__(self, label, publisher_endpoint):
        super(SourceSubscriber, self).__init__()
        self.name = '{}::{}'.format(self.__class__.__name__, label)
        self.daemon = True

        self._label = label
        self._publisher_endpoint = publisher_endpoint

        self.subscriber = zmq_context.socket(zmq.SUB)
        self.processor = zmq_context.socket(zmq.PUSH)
        ZMQEndpoint.__init__(self, zmq_sockets=[self.subscriber, self.processor])

    def run(self):
        log.info('Connecting event processor to {} @ {}'.format(self._label, self._publisher_endpoint))
        self.subscriber.connect(self._publisher_endpoint)
        self.subscriber.setsockopt(zmq.SUBSCRIBE, "")
        self.processor.connect(URL_WORKER_EVENT_PROCESSOR)
        while True:
            try:
                publisher_event = umsgpack.unpackb(self.subscriber.recv())
            except UnpackException:
                log.exception('Cannot unpack message from {}.'.format(self._label))
                continue
            except ContextTerminated:
                break
            log.debug('Event from {}: {}'.format(self._label, publisher_event))
            self.processor.send_pyobj(publisher_event)


if __name__ == "__main__":
    # DEBUG logging until startup complete
    log.setLevel(logging.DEBUG)
    syslog_handler = logging.handlers.SysLogHandler(address='/dev/log')
    formatter = logging.Formatter('%(name)s [%(levelname)s] %(message)s')
    syslog_handler.setFormatter(formatter)
    log.addHandler(syslog_handler)
    if sys.stdout.isatty():
        log.warn("Using console logging because there is a tty.")
        stream_handler = logging.StreamHandler(stream=sys.stdout)
        stream_handler.setFormatter(formatter)
        log.addHandler(stream_handler)
    threads_tracked = Set()
    # bind main processor first
    event_processor = EventProcessor()
    event_processor.start()
    threads_tracked.add(event_processor.getName())
    # set up subscribers
    pubsub_port = config.get('zmq', 'pubsub_port')
    subscription_sources = config.get('app', 'subscription_sources').split(',')
    log.debug('Subscribing to these sources: {}'.format(subscription_sources))
    for source in subscription_sources:
        label_ip = source.split(':')
        source_label = label_ip[0]
        source_ip = label_ip[1]
        connection_string = 'tcp://{}:{}'.format(source_ip, pubsub_port)
        log.info('Creating event subscriber for {} @ {}'.format(source_label, connection_string))
        subscriber = SourceSubscriber(label=source_label, publisher_endpoint=connection_string)
        threads_tracked.add(subscriber.getName())
        subscriber.start()
    # set up signal handlers
    signal.signal(signal.SIGHUP, signal_handler)
    # start threads
    f = threading.Thread(name='flask', target=run_flask)
    f.setDaemon(True)
    f.start()
    threads_tracked.add(f.getName())
    try:
        # startup completed
        # back to INFO logging
        log.setLevel(logging.INFO)
        # connect to publishers
        while True:
            threads_alive = Set()
            for thread_info in threading.enumerate():
                if thread_info.isAlive():
                    threads_alive.add(thread_info.getName())
            if len(threads_tracked - threads_alive) > 0:
                message = 'A thread has died. Expected threads are [{}], missing is [{}].'.format(threads_tracked, threads_tracked - threads_alive)
                log.error(message)
                # bail out
                raise RuntimeError(message)
            time.sleep(10)
    except(KeyboardInterrupt, SystemExit):
        for thread_info in threading.enumerate():
            if thread_info.isAlive() and isinstance(thread_info, ZMQEndpoint):
                log.info("Closing sockets for '{}'".format(thread_info.getName()))
                thread_info.close()
        log.info('Closing subscribers...')
        zmq_context.term()
